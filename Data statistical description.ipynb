{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\spark-3.0.2-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "# pyspark==2.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import sum,avg,max,min,mean\n",
    "from pyspark.sql.functions import row_number,lit\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADMISSIONS      = spark.read.option(\"header\",True).csv('C:\\Health data\\ADMISSIONS.csv')\n",
    "CHARTEVENTS     = spark.read.option(\"header\",True).csv('C:\\Health data\\CHARTEVENTS.csv')\n",
    "DIAGNOSES_ICD   = spark.read.option(\"header\",True).csv('C:\\Health data\\DIAGNOSES_ICD.csv')\n",
    "D_ICD_DIAGNOSES = spark.read.option(\"header\",True).csv('C:\\Health data\\D_ICD_DIAGNOSES.csv')\n",
    "ICUSTAYS        = spark.read.option(\"header\",True).csv('C:\\Health data\\ICUSTAYS.csv')\n",
    "LABEVENTS       = spark.read.option(\"header\",True).csv('C:\\Health data\\LABEVENTS.csv')\n",
    "OUTPUTEVENTS    = spark.read.option(\"header\",True).csv('C:\\Health data\\OUTPUTEVENTS.csv')\n",
    "PATIENTS        = spark.read.option(\"header\",True).csv('C:\\Health data\\PATIENTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many ADMISSIONS recordes:  58976\n",
      "how many patients:  46520\n",
      "how many patients in EMERGENCY:  32610\n",
      "how many Male patients:  26121\n",
      "how many Female patients:  20399\n",
      "how many mortality:  15759\n",
      "how many mortality in EMERGENCY:  14097\n",
      "how many mortality in Non_EMERGENCY:  2699\n"
     ]
    }
   ],
   "source": [
    "####################### Basic ADMISSIONS and PATIENTS Data description ###############################\n",
    "print( \"how many ADMISSIONS recordes: \", ADMISSIONS.select('SUBJECT_ID').count() )\n",
    "print( \"how many patients: \", PATIENTS.select('SUBJECT_ID').distinct().count() )\n",
    "\n",
    "patients_EMERGENCY = ADMISSIONS.filter(ADMISSIONS.ADMISSION_TYPE == 'EMERGENCY')\n",
    "patients_Male = PATIENTS.filter(PATIENTS.GENDER == 'M')\n",
    "patients_Female = PATIENTS.filter(PATIENTS.GENDER == 'F')\n",
    "\n",
    "print(\"how many patients in EMERGENCY: \", patients_EMERGENCY.select('SUBJECT_ID').distinct().count())\n",
    "print(\"how many Male patients: \", patients_Male.select('SUBJECT_ID').distinct().count())\n",
    "print(\"how many Female patients: \", patients_Female.select('SUBJECT_ID').distinct().count())\n",
    "print(\"how many mortality: \", PATIENTS.filter(\"EXPIRE_FLAG == '1'\").select('SUBJECT_ID').distinct().count() )\n",
    "\n",
    "patients_Non_EMERGENCY = ADMISSIONS.filter(ADMISSIONS.ADMISSION_TYPE != 'EMERGENCY').select('SUBJECT_ID').distinct()\n",
    "mortality = PATIENTS.filter(\"EXPIRE_FLAG == '1'\").select('SUBJECT_ID')\n",
    "\n",
    "EMERGENCY_mortality = patients_EMERGENCY.select('SUBJECT_ID').intersect(mortality)\n",
    "Non_EMERGENCY_mortality = patients_Non_EMERGENCY.intersect(mortality)\n",
    "print(\"how many mortality in EMERGENCY: \", EMERGENCY_mortality.select('SUBJECT_ID').distinct().count() )\n",
    "print(\"how many mortality in Non_EMERGENCY: \", Non_EMERGENCY_mortality.select('SUBJECT_ID').distinct().count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how mean ICU stay time of deceased patients:  4.961010863396632\n",
      "how max ICU stay time of deceased patients:  173.0725\n",
      "how min ICU stay time of deceased patients:  0.0001\n",
      "how mean ICU stay time of alive patients:  5.022757566913398\n",
      "how max ICU stay time of alive patients:  171.6227\n",
      "how min ICU stay time of alive patients:  0.0003\n"
     ]
    }
   ],
   "source": [
    "####################### ICUSTAYS Data description ###############################\n",
    "alive_ID     = PATIENTS.filter(\"EXPIRE_FLAG == '0'\").select('SUBJECT_ID').distinct()\n",
    "mortality_ID = PATIENTS.filter(\"EXPIRE_FLAG == '1'\").select('SUBJECT_ID').distinct()\n",
    "ICUSTAYS     = ICUSTAYS.withColumnRenamed(\"SUBJECT_ID\", \"ID\")\n",
    "alive_ID_ICU     = alive_ID.join( ICUSTAYS, alive_ID.SUBJECT_ID == ICUSTAYS.ID,\"left\" )\n",
    "mortality_ID_ICU = mortality_ID.join( ICUSTAYS, mortality_ID.SUBJECT_ID == ICUSTAYS.ID,\"left\" )\n",
    "\n",
    "alive_ID_ICU     = alive_ID_ICU.withColumn(\"LOS\", alive_ID_ICU[\"LOS\"].cast(\"double\"))\n",
    "mortality_ID_ICU = mortality_ID_ICU.withColumn(\"LOS\", mortality_ID_ICU[\"LOS\"].cast(\"double\"))\n",
    "\n",
    "print( \"how mean ICU stay time of deceased patients: \", mortality_ID_ICU.groupBy(\"SUBJECT_ID\").mean(\"LOS\").agg({'avg(LOS)': 'mean'}).rdd.flatMap(list).collect()[0] )\n",
    "print( \"how max ICU stay time of deceased patients: \", mortality_ID_ICU.groupBy(\"SUBJECT_ID\").max(\"LOS\").agg({'max(LOS)': 'max'}).rdd.flatMap(list).collect()[0] )\n",
    "print( \"how min ICU stay time of deceased patients: \", mortality_ID_ICU.groupBy(\"SUBJECT_ID\").min(\"LOS\").agg({'min(LOS)': 'min'}).rdd.flatMap(list).collect()[0] )\n",
    "print( \"how mean ICU stay time of alive patients: \", alive_ID_ICU.groupBy(\"SUBJECT_ID\").mean(\"LOS\").agg({'avg(LOS)': 'mean'}).rdd.flatMap(list).collect()[0] )\n",
    "print( \"how max ICU stay time of alive patients: \", alive_ID_ICU.groupBy(\"SUBJECT_ID\").max(\"LOS\").agg({'max(LOS)': 'max'}).rdd.flatMap(list).collect()[0] )\n",
    "print( \"how min ICU stay time of alive patients: \", alive_ID_ICU.groupBy(\"SUBJECT_ID\").min(\"LOS\").agg({'min(LOS)': 'min'}).rdd.flatMap(list).collect()[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
