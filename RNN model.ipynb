{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "import numpy as np\n",
    "\n",
    "findspark.find()\n",
    "# pyspark==2.4.7\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import sum,avg,max,min,mean\n",
    "from pyspark.sql.functions import row_number,lit\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "from functools import reduce\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, Dataset\n",
    "from functools import reduce\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## read the raw data ##############\n",
    "ADMISSIONS    = spark.read.option(\"header\",True).csv('C:\\Health data\\ADMISSIONS.csv')\n",
    "DIAGNOSES_ICD = spark.read.option(\"header\",True).csv('C:\\Health data\\DIAGNOSES_ICD.csv')\n",
    "PATIENTS      = spark.read.option(\"header\",True).csv('C:\\Health data\\PATIENTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns we need, Admissions data, and rename the columns ###############\n",
    "ADMISSIONS = ADMISSIONS.select('SUBJECT_ID','HADM_ID','ADMITTIME')\n",
    "ADMISSIONS  = ADMISSIONS.withColumnRenamed(\"HADM_ID\", \"ID\")\\\n",
    "                        .withColumnRenamed(\"SUBJECT_ID\", \"Patient_ID\")\n",
    "\n",
    "# conduct the code map for the ICD9_CODE of DIAGNOSES_ICD ###\n",
    "codemap = DIAGNOSES_ICD.select('ICD9_CODE').distinct()\n",
    "w = Window().orderBy(lit('A'))\n",
    "codemap = codemap.withColumn(\"rowNum\", row_number().over(w))\\\n",
    "                 .withColumnRenamed(\"ICD9_CODE\", \"Original_ICD9_CODE\")\\\n",
    "                 .withColumnRenamed(\"rowNum\", \"New_code\")\n",
    "DIAGNOSES_ICD = DIAGNOSES_ICD.join(codemap,DIAGNOSES_ICD.ICD9_CODE==codemap.Original_ICD9_CODE,\"left\")\\\n",
    "                             .select('SUBJECT_ID','HADM_ID','New_code')\n",
    "\n",
    "# Select the columns we need, PATIENTS data, and rename the columns ###### \n",
    "mortality = PATIENTS.select('SUBJECT_ID','EXPIRE_FLAG')\\\n",
    "                    .withColumnRenamed(\"EXPIRE_FLAG\", \"MORTALITY\")\\\n",
    "                    .withColumnRenamed(\"SUBJECT_ID\", \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the ADMISSIONS, DIAGNOSES_ICD, and PATIENTS, based on the SUBJECT_ID and HADM_ID ####   \n",
    "Total_inf1  = DIAGNOSES_ICD.join(mortality, DIAGNOSES_ICD.SUBJECT_ID == mortality.ID,\"left\")\\\n",
    "                           .select(\"SUBJECT_ID\",\"HADM_ID\",\"New_code\",\"MORTALITY\")\n",
    "Total_inf = Total_inf1.join(ADMISSIONS, Total_inf1.HADM_ID == ADMISSIONS.ID,\"left\")\\\n",
    "                      .select('Patient_ID','HADM_ID','New_code','MORTALITY','ADMITTIME')\n",
    "Total_inf = Total_inf.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-9155c3ee5beb>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  gggg = np.array(seqs['feature_value'][i]).flatten().tolist()\n"
     ]
    }
   ],
   "source": [
    "# create the visit sequence dataset ############\n",
    "hu = Total_inf.sort(Total_inf.ADMITTIME.asc()).groupBy(\"Patient_ID\",\"MORTALITY\",\"ADMITTIME\")\\\n",
    "    .agg(F.collect_list(F.struct(\"New_code\")).alias(\"feature_value\"))\\\n",
    "    .withColumn(\"feature_value\", F.expr(\"transform(feature_value, x -> x.New_code)\"))\n",
    "\n",
    "bing = hu.sort(hu.Patient_ID.asc(),hu.ADMITTIME.asc()).groupBy(\"Patient_ID\")\\\n",
    "    .agg(F.collect_list(F.struct(\"feature_value\")).alias(\"feature_value\"))\n",
    "\n",
    "All_data = bing.join( mortality , bing.Patient_ID == mortality.ID, \"left\" )\n",
    "\n",
    "ids    = All_data.select('Patient_ID').toPandas()\n",
    "labels = All_data.select('MORTALITY').toPandas()\n",
    "seqs   = All_data.select('feature_value').toPandas()\n",
    "\n",
    "train_ids    = []\n",
    "train_labels = []\n",
    "train_seqs   = []\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    train_ids.append(int(ids['Patient_ID'][i]))\n",
    "    train_labels.append(int(labels['MORTALITY'][i]))\n",
    "    gggg = np.array(seqs['feature_value'][i]).flatten().tolist()    \n",
    "    train_seqs.append( gggg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = Total_inf.select(\"New_code\").distinct().count() + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisitSequenceWithLabelDataset(Dataset):\n",
    "    def __init__(self, seqs, labels, num_features):\n",
    "        if len(seqs) != len(labels):\n",
    "            raise ValueError(\"Seqs and Labels have different lengths\")\n",
    "        self.labels = labels\n",
    "        answers = []\n",
    "        for x in seqs:\n",
    "            a = len(x)\n",
    "            b = num_features\n",
    "            mtx = np.zeros((a, b))\n",
    "            each_line = 0\n",
    "            for ets in x:\n",
    "                mtx[each_line, ets] = 1\n",
    "                each_line = each_line + 1\n",
    "            answers.append(mtx)\n",
    "            self.seqs = answers\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns will be wrapped as List of Tensor(s) by DataLoader\n",
    "        return self.seqs[index], self.labels[index]\n",
    "\n",
    "def visit_collate_fn(batch):\n",
    "    x = 0\n",
    "    lines = []\n",
    "    for a, b in batch:\n",
    "        lines.append((a.shape[0], x))\n",
    "        x = x + 1\n",
    "    lines.sort(key = lambda s: s[0], reverse=True)\n",
    "    line_row = lines[0][0]\n",
    "    line_col = batch[0][0].shape[1]\n",
    "    listOne = []\n",
    "    listTwo = []\n",
    "    listThree = []\n",
    "    for i in list(map(lambda s: s[1], lines)):\n",
    "        patient = batch[i]\n",
    "        listTwo.append(patient[1])\n",
    "        listThree.append(patient[0].shape[0])\n",
    "        d = np.zeros((line_row, line_col))\n",
    "        d[0:patient[0].shape[0], 0:patient[0].shape[1]] = patient[0]\n",
    "        listOne.append(d)\n",
    "\n",
    "    seqs_tensor = torch.FloatTensor(listOne)\n",
    "    lengths_tensor = torch.LongTensor(listThree)\n",
    "    labels_tensor = torch.LongTensor(listTwo)\n",
    "    #print(listTwo)\n",
    "\n",
    "    return (seqs_tensor, lengths_tensor), labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VisitSequenceWithLabelDataset(train_seqs[0:10000], train_labels[0:10000], num_features)\n",
    "train_loader  = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, collate_fn=visit_collate_fn, num_workers=0)\n",
    "valid_dataset = VisitSequenceWithLabelDataset(train_seqs[25001:27000], train_labels[25001:27000], num_features)\n",
    "test_dataset  = VisitSequenceWithLabelDataset(train_seqs[27001:30000], train_labels[27001:30000], num_features)\n",
    "valid_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False, collate_fn=visit_collate_fn, num_workers=0)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, collate_fn=visit_collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNN model construction, training, and evaluation ###########\n",
    "class MyRNN1(nn.Module):\n",
    "    def __init__(self, dim_input):\n",
    "        super(MyRNN1, self).__init__()\n",
    "        self.input_layer1 = nn.Linear(in_features=dim_input, out_features=32)\n",
    "        self.rnn_model    = nn.GRU(input_size=32, hidden_size=16, num_layers=1, batch_first=True)\n",
    "        self.input_layer2 = nn.Linear(in_features=16, out_features=2) \n",
    "\n",
    "    def forward(self, input_tuple):\n",
    "        seqs, lengths = input_tuple\n",
    "        seqs          = torch.tanh(self.input_layer1(seqs)) \n",
    "        seqs          = pack_padded_sequence(seqs, lengths, batch_first=True) \n",
    "        seqs, h       = self.rnn_model(seqs)\n",
    "        seqs, _       = pad_packed_sequence(seqs, batch_first=True)\n",
    "        seqs          = self.input_layer2(seqs[:, -1, :])\n",
    "        return seqs\n",
    "\n",
    "\n",
    "class MyRNN2(nn.Module):\n",
    "    def __init__(self, dim_input):\n",
    "        super(MyRNN2, self).__init__()\n",
    "\n",
    "        self.batch_first =True\n",
    "        self.layer1 = nn.Sequential(nn.Dropout(p=0.8),nn.Linear(dim_input, 128, bias=False),nn.Dropout(p=0.5))\n",
    "        self.rnn1 = nn.GRU(input_size=128, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.rnnl1 = nn.Linear(in_features=128, out_features=1)\n",
    "        self.rnnl1.bias.data.zero_()\n",
    "        self.rnn2 = nn.GRU(input_size=128, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.rnnl2 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.rnnl2.bias.data.zero_()\n",
    "        self.rnno = nn.Sequential(nn.Dropout(p=0.5),nn.Linear(in_features=128, out_features=2))\n",
    "        self.rnno[1].bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_tuple):\n",
    "        seqs, lengths = input_tuple\n",
    "        b1, m1 = seqs.size()[:2]\n",
    "        x = self.layer1(seqs)\n",
    "        pi = pack_padded_sequence(x, lengths, batch_first=self.batch_first)\n",
    "        a, _ = self.rnn1(pi)\n",
    "        b, _ = pad_packed_sequence(a, batch_first=self.batch_first)\n",
    "        c = torch.autograd.Variable(torch.FloatTensor([[1.0 if i < lengths[idx] else 0.0 for i in range(m1)] for idx in range(b1)]).unsqueeze(2), requires_grad=False)\n",
    "        e = self.rnnl1(b)\n",
    "        def max(x, c):\n",
    "            exp = torch.exp(x)\n",
    "            msp = exp * c\n",
    "            sth = torch.sum(msp, dim=1, keepdim=True)\n",
    "            return msp / sth\n",
    "        alpha = max(e, c)\n",
    "        h, _ = self.rnn2(pi)\n",
    "        gps, _ = pad_packed_sequence(h, batch_first=self.batch_first)\n",
    "        out = torch.tanh(self.rnnl2(gps))\n",
    "        context = torch.bmm(torch.transpose(alpha, 1, 2), out * x).squeeze(1)\n",
    "        rnno = self.rnno(context)\n",
    "        return rnno\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def compute_batch_accuracy(output, target):\n",
    "    \"\"\"Computes the accuracy for a batch\"\"\"\n",
    "    with torch.no_grad():\n",
    "\n",
    "        batch_size = target.size(0)\n",
    "        _, pred = output.max(1)\n",
    "        correct = pred.eq(target).sum()\n",
    "\n",
    "        return correct * 100.0 / batch_size\n",
    "\n",
    "\n",
    "def train(model, device, data_loader, criterion, optimizer, epoch, print_freq=10):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(data_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if isinstance(input, tuple):\n",
    "            input = tuple([e.to(device) if type(e) == torch.Tensor else e for e in input])\n",
    "        else:\n",
    "            input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        losses.update(loss.item(), target.size(0))\n",
    "        accuracy.update(compute_batch_accuracy(output, target).item(), target.size(0))\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Accuracy {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                epoch, i, len(data_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses, acc=accuracy))\n",
    "\n",
    "    return losses.avg, accuracy.avg\n",
    "\n",
    "\n",
    "def evaluate(model, device, data_loader, criterion, print_freq=10):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(data_loader):\n",
    "\n",
    "            if isinstance(input, tuple):\n",
    "                input = tuple([e.to(device) if type(e) == torch.Tensor else e for e in input])\n",
    "            else:\n",
    "                input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            losses.update(loss.item(), target.size(0))\n",
    "            accuracy.update(compute_batch_accuracy(output, target).item(), target.size(0))\n",
    "\n",
    "            y_true = target.detach().to('cpu').numpy().tolist()\n",
    "            y_pred = output.detach().to('cpu').max(1)[1].numpy().tolist()\n",
    "            results.extend(list(zip(y_true, y_pred)))\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Accuracy {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                    i, len(data_loader), batch_time=batch_time, loss=losses, acc=accuracy))\n",
    "\n",
    "    return losses.avg, accuracy.avg, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and USE_CUDA else \"cpu\")\n",
    "torch.manual_seed(1)\n",
    "if device.type == \"cuda\":\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "model = MyRNN2(num_features)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/313]\tTime 1.219 (1.219)\tData 0.786 (0.786)\tLoss 0.6932 (0.6932)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [0][10/313]\tTime 1.546 (1.205)\tData 1.134 (0.877)\tLoss 0.6915 (0.6922)\tAccuracy 59.375 (61.080)\n",
      "Epoch: [0][20/313]\tTime 1.726 (1.203)\tData 1.307 (0.882)\tLoss 0.6852 (0.6907)\tAccuracy 71.875 (63.244)\n",
      "Epoch: [0][30/313]\tTime 1.010 (1.177)\tData 0.786 (0.863)\tLoss 0.6862 (0.6896)\tAccuracy 62.500 (63.206)\n",
      "Epoch: [0][40/313]\tTime 1.583 (1.171)\tData 1.164 (0.859)\tLoss 0.6893 (0.6883)\tAccuracy 56.250 (63.643)\n",
      "Epoch: [0][50/313]\tTime 1.017 (1.168)\tData 0.747 (0.858)\tLoss 0.6736 (0.6869)\tAccuracy 71.875 (64.093)\n",
      "Epoch: [0][60/313]\tTime 1.251 (1.165)\tData 0.927 (0.853)\tLoss 0.6642 (0.6855)\tAccuracy 75.000 (64.447)\n",
      "Epoch: [0][70/313]\tTime 1.105 (1.172)\tData 0.810 (0.859)\tLoss 0.6600 (0.6839)\tAccuracy 75.000 (64.877)\n",
      "Epoch: [0][80/313]\tTime 1.006 (1.146)\tData 0.742 (0.840)\tLoss 0.6506 (0.6819)\tAccuracy 71.875 (65.162)\n",
      "Epoch: [0][90/313]\tTime 1.053 (1.161)\tData 0.759 (0.851)\tLoss 0.6468 (0.6800)\tAccuracy 71.875 (65.316)\n",
      "Epoch: [0][100/313]\tTime 0.752 (1.150)\tData 0.548 (0.843)\tLoss 0.6814 (0.6780)\tAccuracy 62.500 (65.347)\n",
      "Epoch: [0][110/313]\tTime 0.976 (1.145)\tData 0.722 (0.840)\tLoss 0.6767 (0.6777)\tAccuracy 62.500 (65.456)\n",
      "Epoch: [0][120/313]\tTime 1.195 (1.133)\tData 0.876 (0.831)\tLoss 0.6654 (0.6781)\tAccuracy 65.625 (65.160)\n",
      "Epoch: [0][130/313]\tTime 1.001 (1.137)\tData 0.720 (0.834)\tLoss 0.6944 (0.6771)\tAccuracy 62.500 (65.219)\n",
      "Epoch: [0][140/313]\tTime 0.994 (1.132)\tData 0.722 (0.830)\tLoss 0.6939 (0.6762)\tAccuracy 56.250 (65.160)\n",
      "Epoch: [0][150/313]\tTime 0.963 (1.132)\tData 0.717 (0.830)\tLoss 0.6625 (0.6745)\tAccuracy 65.625 (65.418)\n",
      "Epoch: [0][160/313]\tTime 1.021 (1.135)\tData 0.648 (0.832)\tLoss 0.6537 (0.6734)\tAccuracy 71.875 (65.509)\n",
      "Epoch: [0][170/313]\tTime 0.841 (1.134)\tData 0.632 (0.831)\tLoss 0.6708 (0.6720)\tAccuracy 59.375 (65.625)\n",
      "Epoch: [0][180/313]\tTime 1.239 (1.133)\tData 0.912 (0.831)\tLoss 0.6535 (0.6706)\tAccuracy 65.625 (65.711)\n",
      "Epoch: [0][190/313]\tTime 1.229 (1.129)\tData 0.881 (0.828)\tLoss 0.6743 (0.6694)\tAccuracy 56.250 (65.690)\n",
      "Epoch: [0][200/313]\tTime 1.117 (1.132)\tData 0.843 (0.829)\tLoss 0.6912 (0.6697)\tAccuracy 65.625 (65.516)\n",
      "Epoch: [0][210/313]\tTime 1.165 (1.129)\tData 0.848 (0.827)\tLoss 0.5932 (0.6693)\tAccuracy 81.250 (65.551)\n",
      "Epoch: [0][220/313]\tTime 1.109 (1.132)\tData 0.769 (0.828)\tLoss 0.6518 (0.6683)\tAccuracy 62.500 (65.568)\n",
      "Epoch: [0][230/313]\tTime 1.051 (1.136)\tData 0.772 (0.831)\tLoss 0.6282 (0.6677)\tAccuracy 68.750 (65.557)\n",
      "Epoch: [0][240/313]\tTime 1.025 (1.152)\tData 0.728 (0.842)\tLoss 0.6505 (0.6669)\tAccuracy 65.625 (65.651)\n",
      "Epoch: [0][250/313]\tTime 1.538 (1.160)\tData 1.092 (0.847)\tLoss 0.6711 (0.6666)\tAccuracy 59.375 (65.538)\n",
      "Epoch: [0][260/313]\tTime 1.550 (1.172)\tData 1.107 (0.855)\tLoss 0.6041 (0.6655)\tAccuracy 75.000 (65.661)\n",
      "Epoch: [0][270/313]\tTime 1.072 (1.180)\tData 0.776 (0.861)\tLoss 0.5855 (0.6639)\tAccuracy 75.000 (65.844)\n",
      "Epoch: [0][280/313]\tTime 1.063 (1.177)\tData 0.751 (0.859)\tLoss 0.8527 (0.6649)\tAccuracy 56.250 (65.658)\n",
      "Epoch: [0][290/313]\tTime 1.024 (1.172)\tData 0.762 (0.854)\tLoss 0.6260 (0.6641)\tAccuracy 71.875 (65.711)\n",
      "Epoch: [0][300/313]\tTime 1.013 (1.175)\tData 0.737 (0.857)\tLoss 0.6815 (0.6641)\tAccuracy 59.375 (65.708)\n",
      "Epoch: [0][310/313]\tTime 1.041 (1.182)\tData 0.728 (0.862)\tLoss 0.6192 (0.6634)\tAccuracy 71.875 (65.746)\n",
      "Test: [0/313]\tTime 0.727 (0.727)\tLoss 0.6699 (0.6699)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 0.968 (0.831)\tLoss 0.6089 (0.6611)\tAccuracy 75.000 (63.352)\n",
      "Test: [20/313]\tTime 0.850 (0.832)\tLoss 0.6305 (0.6575)\tAccuracy 68.750 (63.244)\n",
      "Test: [30/313]\tTime 0.592 (0.813)\tLoss 0.6848 (0.6563)\tAccuracy 56.250 (63.609)\n",
      "Test: [40/313]\tTime 0.823 (0.831)\tLoss 0.6853 (0.6561)\tAccuracy 59.375 (63.720)\n",
      "Test: [50/313]\tTime 1.215 (0.840)\tLoss 0.6466 (0.6551)\tAccuracy 65.625 (64.032)\n",
      "Test: [60/313]\tTime 1.076 (0.866)\tLoss 0.6561 (0.6522)\tAccuracy 62.500 (64.652)\n",
      "Test: [70/313]\tTime 1.092 (0.874)\tLoss 0.6520 (0.6516)\tAccuracy 65.625 (64.833)\n",
      "Test: [80/313]\tTime 0.780 (0.895)\tLoss 0.7095 (0.6504)\tAccuracy 53.125 (65.085)\n",
      "Test: [90/313]\tTime 0.895 (0.908)\tLoss 0.6398 (0.6490)\tAccuracy 65.625 (65.350)\n",
      "Test: [100/313]\tTime 1.626 (0.943)\tLoss 0.6207 (0.6485)\tAccuracy 71.875 (65.470)\n",
      "Test: [110/313]\tTime 0.733 (0.966)\tLoss 0.6239 (0.6475)\tAccuracy 65.625 (65.653)\n",
      "Test: [120/313]\tTime 1.849 (0.980)\tLoss 0.5991 (0.6469)\tAccuracy 75.000 (65.754)\n",
      "Test: [130/313]\tTime 0.790 (0.985)\tLoss 0.6329 (0.6474)\tAccuracy 68.750 (65.649)\n",
      "Test: [140/313]\tTime 0.604 (0.994)\tLoss 0.6192 (0.6476)\tAccuracy 71.875 (65.581)\n",
      "Test: [150/313]\tTime 0.859 (0.994)\tLoss 0.6680 (0.6469)\tAccuracy 62.500 (65.728)\n",
      "Test: [160/313]\tTime 1.033 (1.007)\tLoss 0.6546 (0.6455)\tAccuracy 65.625 (66.110)\n",
      "Test: [170/313]\tTime 0.794 (0.998)\tLoss 0.6865 (0.6460)\tAccuracy 56.250 (66.009)\n",
      "Test: [180/313]\tTime 1.174 (1.003)\tLoss 0.6047 (0.6461)\tAccuracy 75.000 (65.970)\n",
      "Test: [190/313]\tTime 0.622 (1.000)\tLoss 0.7144 (0.6463)\tAccuracy 50.000 (65.936)\n",
      "Test: [200/313]\tTime 1.328 (0.993)\tLoss 0.5978 (0.6468)\tAccuracy 78.125 (65.827)\n",
      "Test: [210/313]\tTime 1.495 (1.005)\tLoss 0.6597 (0.6466)\tAccuracy 65.625 (65.906)\n",
      "Test: [220/313]\tTime 0.863 (1.012)\tLoss 0.7299 (0.6477)\tAccuracy 46.875 (65.639)\n",
      "Test: [230/313]\tTime 0.699 (1.024)\tLoss 0.6765 (0.6472)\tAccuracy 59.375 (65.747)\n",
      "Test: [240/313]\tTime 1.203 (1.021)\tLoss 0.6417 (0.6471)\tAccuracy 68.750 (65.794)\n",
      "Test: [250/313]\tTime 0.706 (1.021)\tLoss 0.6008 (0.6473)\tAccuracy 75.000 (65.762)\n",
      "Test: [260/313]\tTime 0.657 (1.012)\tLoss 0.6164 (0.6470)\tAccuracy 71.875 (65.841)\n",
      "Test: [270/313]\tTime 0.975 (1.007)\tLoss 0.5659 (0.6466)\tAccuracy 84.375 (65.890)\n",
      "Test: [280/313]\tTime 1.032 (1.010)\tLoss 0.6938 (0.6465)\tAccuracy 56.250 (65.914)\n",
      "Test: [290/313]\tTime 0.686 (1.005)\tLoss 0.7303 (0.6474)\tAccuracy 46.875 (65.689)\n",
      "Test: [300/313]\tTime 0.789 (1.005)\tLoss 0.6664 (0.6475)\tAccuracy 62.500 (65.687)\n",
      "Test: [310/313]\tTime 0.810 (1.001)\tLoss 0.6317 (0.6473)\tAccuracy 68.750 (65.695)\n",
      "Epoch: [1][0/313]\tTime 1.065 (1.065)\tData 0.719 (0.719)\tLoss 0.6643 (0.6643)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [1][10/313]\tTime 1.043 (1.213)\tData 0.772 (0.880)\tLoss 0.6906 (0.6697)\tAccuracy 56.250 (61.080)\n",
      "Epoch: [1][20/313]\tTime 0.773 (1.260)\tData 0.557 (0.907)\tLoss 0.5893 (0.6564)\tAccuracy 75.000 (63.839)\n",
      "Epoch: [1][30/313]\tTime 1.222 (1.214)\tData 0.888 (0.872)\tLoss 0.6651 (0.6545)\tAccuracy 59.375 (64.516)\n",
      "Epoch: [1][40/313]\tTime 1.328 (1.234)\tData 0.940 (0.885)\tLoss 0.7001 (0.6549)\tAccuracy 53.125 (64.405)\n",
      "Epoch: [1][50/313]\tTime 1.261 (1.225)\tData 0.880 (0.877)\tLoss 0.6561 (0.6522)\tAccuracy 65.625 (64.767)\n",
      "Epoch: [1][60/313]\tTime 0.895 (1.213)\tData 0.645 (0.869)\tLoss 0.7046 (0.6542)\tAccuracy 53.125 (64.293)\n",
      "Epoch: [1][70/313]\tTime 1.578 (1.227)\tData 1.121 (0.878)\tLoss 0.6878 (0.6501)\tAccuracy 56.250 (65.097)\n",
      "Epoch: [1][80/313]\tTime 1.777 (1.221)\tData 1.346 (0.874)\tLoss 0.5397 (0.6474)\tAccuracy 87.500 (65.548)\n",
      "Epoch: [1][90/313]\tTime 1.081 (1.225)\tData 0.757 (0.878)\tLoss 0.6625 (0.6490)\tAccuracy 59.375 (65.247)\n",
      "Epoch: [1][100/313]\tTime 1.489 (1.217)\tData 1.060 (0.873)\tLoss 0.6988 (0.6483)\tAccuracy 56.250 (65.408)\n",
      "Epoch: [1][110/313]\tTime 0.920 (1.217)\tData 0.667 (0.871)\tLoss 0.6324 (0.6497)\tAccuracy 68.750 (65.146)\n",
      "Epoch: [1][120/313]\tTime 0.972 (1.205)\tData 0.696 (0.862)\tLoss 0.6446 (0.6505)\tAccuracy 65.625 (64.954)\n",
      "Epoch: [1][130/313]\tTime 0.790 (1.195)\tData 0.585 (0.856)\tLoss 0.6729 (0.6498)\tAccuracy 59.375 (65.076)\n",
      "Epoch: [1][140/313]\tTime 1.022 (1.193)\tData 0.708 (0.854)\tLoss 0.6227 (0.6477)\tAccuracy 68.750 (65.448)\n",
      "Epoch: [1][150/313]\tTime 1.094 (1.188)\tData 0.798 (0.850)\tLoss 0.6125 (0.6471)\tAccuracy 71.875 (65.584)\n",
      "Epoch: [1][160/313]\tTime 0.900 (1.181)\tData 0.635 (0.845)\tLoss 0.6387 (0.6474)\tAccuracy 65.625 (65.509)\n",
      "Epoch: [1][170/313]\tTime 1.374 (1.188)\tData 0.996 (0.849)\tLoss 0.6651 (0.6466)\tAccuracy 62.500 (65.680)\n",
      "Epoch: [1][180/313]\tTime 1.277 (1.194)\tData 0.911 (0.853)\tLoss 0.6474 (0.6471)\tAccuracy 68.750 (65.608)\n",
      "Epoch: [1][190/313]\tTime 0.960 (1.195)\tData 0.705 (0.854)\tLoss 0.6107 (0.6477)\tAccuracy 71.875 (65.527)\n",
      "Epoch: [1][200/313]\tTime 1.019 (1.195)\tData 0.726 (0.854)\tLoss 0.6860 (0.6460)\tAccuracy 56.250 (65.734)\n",
      "Epoch: [1][210/313]\tTime 1.003 (1.197)\tData 0.718 (0.855)\tLoss 0.5788 (0.6465)\tAccuracy 75.000 (65.625)\n",
      "Epoch: [1][220/313]\tTime 1.050 (1.194)\tData 0.757 (0.853)\tLoss 0.6184 (0.6467)\tAccuracy 68.750 (65.597)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][230/313]\tTime 0.900 (1.191)\tData 0.627 (0.851)\tLoss 0.6241 (0.6459)\tAccuracy 68.750 (65.720)\n",
      "Epoch: [1][240/313]\tTime 0.972 (1.190)\tData 0.706 (0.850)\tLoss 0.5348 (0.6452)\tAccuracy 84.375 (65.845)\n",
      "Epoch: [1][250/313]\tTime 0.761 (1.185)\tData 0.538 (0.847)\tLoss 0.7254 (0.6453)\tAccuracy 53.125 (65.824)\n",
      "Epoch: [1][260/313]\tTime 1.277 (1.183)\tData 0.903 (0.846)\tLoss 0.5763 (0.6448)\tAccuracy 75.000 (65.912)\n",
      "Epoch: [1][270/313]\tTime 1.207 (1.189)\tData 0.847 (0.850)\tLoss 0.6699 (0.6452)\tAccuracy 59.375 (65.844)\n",
      "Epoch: [1][280/313]\tTime 1.189 (1.188)\tData 0.859 (0.849)\tLoss 0.5808 (0.6452)\tAccuracy 75.000 (65.825)\n",
      "Epoch: [1][290/313]\tTime 1.108 (1.195)\tData 0.770 (0.855)\tLoss 0.5654 (0.6455)\tAccuracy 78.125 (65.765)\n",
      "Epoch: [1][300/313]\tTime 1.401 (1.197)\tData 1.014 (0.856)\tLoss 0.6065 (0.6462)\tAccuracy 71.875 (65.635)\n",
      "Epoch: [1][310/313]\tTime 2.054 (1.214)\tData 1.413 (0.868)\tLoss 0.6272 (0.6455)\tAccuracy 68.750 (65.725)\n",
      "Test: [0/313]\tTime 0.912 (0.912)\tLoss 0.6800 (0.6800)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 1.195 (1.037)\tLoss 0.5926 (0.6583)\tAccuracy 75.000 (63.352)\n",
      "Test: [20/313]\tTime 1.056 (1.108)\tLoss 0.6205 (0.6554)\tAccuracy 68.750 (63.244)\n",
      "Test: [30/313]\tTime 0.767 (1.079)\tLoss 0.6947 (0.6540)\tAccuracy 56.250 (63.609)\n",
      "Test: [40/313]\tTime 1.127 (1.099)\tLoss 0.6856 (0.6534)\tAccuracy 59.375 (63.720)\n",
      "Test: [50/313]\tTime 1.598 (1.104)\tLoss 0.6413 (0.6518)\tAccuracy 65.625 (64.032)\n",
      "Test: [60/313]\tTime 1.245 (1.105)\tLoss 0.6556 (0.6481)\tAccuracy 62.500 (64.652)\n",
      "Test: [70/313]\tTime 1.304 (1.113)\tLoss 0.6434 (0.6471)\tAccuracy 65.625 (64.833)\n",
      "Test: [80/313]\tTime 0.699 (1.117)\tLoss 0.7174 (0.6456)\tAccuracy 53.125 (65.085)\n",
      "Test: [90/313]\tTime 0.912 (1.114)\tLoss 0.6352 (0.6438)\tAccuracy 65.625 (65.350)\n",
      "Test: [100/313]\tTime 1.370 (1.120)\tLoss 0.6062 (0.6432)\tAccuracy 71.875 (65.470)\n",
      "Test: [110/313]\tTime 0.816 (1.116)\tLoss 0.6293 (0.6420)\tAccuracy 65.625 (65.653)\n",
      "Test: [120/313]\tTime 1.736 (1.113)\tLoss 0.5811 (0.6413)\tAccuracy 75.000 (65.754)\n",
      "Test: [130/313]\tTime 0.848 (1.123)\tLoss 0.6233 (0.6420)\tAccuracy 68.750 (65.649)\n",
      "Test: [140/313]\tTime 0.756 (1.120)\tLoss 0.6094 (0.6422)\tAccuracy 71.875 (65.581)\n",
      "Test: [150/313]\tTime 0.789 (1.110)\tLoss 0.6647 (0.6414)\tAccuracy 62.500 (65.728)\n",
      "Test: [160/313]\tTime 0.917 (1.122)\tLoss 0.6425 (0.6393)\tAccuracy 65.625 (66.110)\n",
      "Test: [170/313]\tTime 0.777 (1.108)\tLoss 0.6956 (0.6400)\tAccuracy 56.250 (66.009)\n",
      "Test: [180/313]\tTime 2.311 (1.112)\tLoss 0.5833 (0.6401)\tAccuracy 75.000 (65.970)\n",
      "Test: [190/313]\tTime 0.771 (1.114)\tLoss 0.7281 (0.6403)\tAccuracy 50.000 (65.936)\n",
      "Test: [200/313]\tTime 1.124 (1.104)\tLoss 0.5747 (0.6409)\tAccuracy 78.125 (65.827)\n",
      "Test: [210/313]\tTime 1.231 (1.103)\tLoss 0.6470 (0.6405)\tAccuracy 65.625 (65.906)\n",
      "Test: [220/313]\tTime 0.770 (1.107)\tLoss 0.7487 (0.6420)\tAccuracy 46.875 (65.639)\n",
      "Test: [230/313]\tTime 0.873 (1.121)\tLoss 0.6800 (0.6414)\tAccuracy 59.375 (65.747)\n",
      "Test: [240/313]\tTime 1.608 (1.130)\tLoss 0.6314 (0.6412)\tAccuracy 68.750 (65.794)\n",
      "Test: [250/313]\tTime 1.016 (1.146)\tLoss 0.5851 (0.6413)\tAccuracy 75.000 (65.762)\n",
      "Test: [260/313]\tTime 1.118 (1.152)\tLoss 0.6026 (0.6409)\tAccuracy 71.875 (65.841)\n",
      "Test: [270/313]\tTime 1.255 (1.154)\tLoss 0.5321 (0.6405)\tAccuracy 84.375 (65.890)\n",
      "Test: [280/313]\tTime 1.276 (1.156)\tLoss 0.7019 (0.6403)\tAccuracy 56.250 (65.914)\n",
      "Test: [290/313]\tTime 0.740 (1.154)\tLoss 0.7458 (0.6416)\tAccuracy 46.875 (65.689)\n",
      "Test: [300/313]\tTime 1.050 (1.163)\tLoss 0.6625 (0.6416)\tAccuracy 62.500 (65.687)\n",
      "Test: [310/313]\tTime 1.042 (1.163)\tLoss 0.6224 (0.6415)\tAccuracy 68.750 (65.695)\n",
      "Epoch: [2][0/313]\tTime 1.341 (1.341)\tData 0.883 (0.883)\tLoss 0.6614 (0.6614)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [2][10/313]\tTime 1.888 (1.532)\tData 1.412 (1.114)\tLoss 0.6117 (0.6575)\tAccuracy 68.750 (62.784)\n",
      "Epoch: [2][20/313]\tTime 1.429 (1.525)\tData 1.063 (1.116)\tLoss 0.6337 (0.6535)\tAccuracy 68.750 (63.839)\n",
      "Epoch: [2][30/313]\tTime 1.409 (1.456)\tData 0.973 (1.060)\tLoss 0.6318 (0.6494)\tAccuracy 68.750 (64.516)\n",
      "Epoch: [2][40/313]\tTime 1.611 (1.464)\tData 1.256 (1.067)\tLoss 0.6228 (0.6490)\tAccuracy 65.625 (64.482)\n",
      "Epoch: [2][50/313]\tTime 1.490 (1.508)\tData 1.125 (1.103)\tLoss 0.6726 (0.6457)\tAccuracy 59.375 (65.012)\n",
      "Epoch: [2][60/313]\tTime 1.396 (1.498)\tData 1.004 (1.091)\tLoss 0.5939 (0.6432)\tAccuracy 71.875 (65.369)\n",
      "Epoch: [2][70/313]\tTime 1.345 (1.500)\tData 0.979 (1.091)\tLoss 0.6261 (0.6424)\tAccuracy 68.750 (65.537)\n",
      "Epoch: [2][80/313]\tTime 1.448 (1.520)\tData 1.054 (1.108)\tLoss 0.6850 (0.6422)\tAccuracy 59.375 (65.664)\n",
      "Epoch: [2][90/313]\tTime 1.396 (1.525)\tData 1.014 (1.113)\tLoss 0.6877 (0.6421)\tAccuracy 59.375 (65.694)\n",
      "Epoch: [2][100/313]\tTime 1.143 (1.524)\tData 0.827 (1.113)\tLoss 0.5589 (0.6416)\tAccuracy 78.125 (65.718)\n",
      "Epoch: [2][110/313]\tTime 1.617 (1.519)\tData 1.152 (1.109)\tLoss 0.6710 (0.6435)\tAccuracy 62.500 (65.400)\n",
      "Epoch: [2][120/313]\tTime 1.075 (1.511)\tData 0.791 (1.103)\tLoss 0.5449 (0.6449)\tAccuracy 81.250 (65.238)\n",
      "Epoch: [2][130/313]\tTime 2.057 (1.508)\tData 1.599 (1.101)\tLoss 0.5715 (0.6433)\tAccuracy 78.125 (65.458)\n",
      "Epoch: [2][140/313]\tTime 1.153 (1.500)\tData 0.824 (1.095)\tLoss 0.5896 (0.6405)\tAccuracy 71.875 (65.869)\n",
      "Epoch: [2][150/313]\tTime 1.752 (1.521)\tData 1.268 (1.110)\tLoss 0.7505 (0.6410)\tAccuracy 53.125 (65.894)\n",
      "Epoch: [2][160/313]\tTime 1.605 (1.543)\tData 1.208 (1.128)\tLoss 0.5843 (0.6406)\tAccuracy 75.000 (65.994)\n",
      "Epoch: [2][170/313]\tTime 2.098 (1.543)\tData 1.599 (1.127)\tLoss 0.6223 (0.6412)\tAccuracy 68.750 (65.936)\n",
      "Epoch: [2][180/313]\tTime 1.584 (1.538)\tData 1.162 (1.124)\tLoss 0.6086 (0.6411)\tAccuracy 68.750 (65.919)\n",
      "Epoch: [2][190/313]\tTime 1.780 (1.535)\tData 1.248 (1.121)\tLoss 0.6285 (0.6404)\tAccuracy 68.750 (66.050)\n",
      "Epoch: [2][200/313]\tTime 1.540 (1.528)\tData 1.130 (1.116)\tLoss 0.6785 (0.6417)\tAccuracy 62.500 (65.843)\n",
      "Epoch: [2][210/313]\tTime 1.062 (1.524)\tData 0.781 (1.114)\tLoss 0.6057 (0.6416)\tAccuracy 71.875 (65.877)\n",
      "Epoch: [2][220/313]\tTime 1.108 (1.520)\tData 0.815 (1.111)\tLoss 0.6450 (0.6410)\tAccuracy 65.625 (65.964)\n",
      "Epoch: [2][230/313]\tTime 1.502 (1.513)\tData 1.071 (1.107)\tLoss 0.6308 (0.6422)\tAccuracy 68.750 (65.828)\n",
      "Epoch: [2][240/313]\tTime 1.326 (1.508)\tData 0.987 (1.103)\tLoss 0.6718 (0.6426)\tAccuracy 59.375 (65.755)\n",
      "Epoch: [2][250/313]\tTime 2.211 (1.515)\tData 1.600 (1.108)\tLoss 0.5233 (0.6420)\tAccuracy 84.375 (65.837)\n",
      "Epoch: [2][260/313]\tTime 1.423 (1.513)\tData 1.026 (1.106)\tLoss 0.6437 (0.6420)\tAccuracy 65.625 (65.852)\n",
      "Epoch: [2][270/313]\tTime 1.388 (1.515)\tData 1.033 (1.108)\tLoss 0.6294 (0.6422)\tAccuracy 71.875 (65.798)\n",
      "Epoch: [2][280/313]\tTime 1.472 (1.512)\tData 1.045 (1.105)\tLoss 0.6617 (0.6419)\tAccuracy 65.625 (65.847)\n",
      "Epoch: [2][290/313]\tTime 1.228 (1.505)\tData 0.903 (1.099)\tLoss 0.8131 (0.6428)\tAccuracy 37.500 (65.700)\n",
      "Epoch: [2][300/313]\tTime 1.286 (1.503)\tData 0.931 (1.098)\tLoss 0.6728 (0.6427)\tAccuracy 59.375 (65.718)\n",
      "Epoch: [2][310/313]\tTime 1.665 (1.500)\tData 1.237 (1.095)\tLoss 0.7254 (0.6428)\tAccuracy 53.125 (65.705)\n",
      "Test: [0/313]\tTime 0.981 (0.981)\tLoss 0.6817 (0.6817)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 1.190 (0.993)\tLoss 0.5836 (0.6559)\tAccuracy 75.000 (63.352)\n",
      "Test: [20/313]\tTime 1.042 (1.006)\tLoss 0.6218 (0.6549)\tAccuracy 68.750 (63.244)\n",
      "Test: [30/313]\tTime 0.823 (1.012)\tLoss 0.7003 (0.6527)\tAccuracy 56.250 (63.609)\n",
      "Test: [40/313]\tTime 1.091 (1.036)\tLoss 0.6822 (0.6521)\tAccuracy 59.375 (63.720)\n",
      "Test: [50/313]\tTime 1.600 (1.041)\tLoss 0.6388 (0.6503)\tAccuracy 65.625 (64.032)\n",
      "Test: [60/313]\tTime 1.408 (1.054)\tLoss 0.6598 (0.6467)\tAccuracy 62.500 (64.652)\n",
      "Test: [70/313]\tTime 1.338 (1.061)\tLoss 0.6376 (0.6455)\tAccuracy 65.625 (64.833)\n",
      "Test: [80/313]\tTime 0.650 (1.057)\tLoss 0.7163 (0.6438)\tAccuracy 53.125 (65.085)\n",
      "Test: [90/313]\tTime 0.788 (1.051)\tLoss 0.6395 (0.6422)\tAccuracy 65.625 (65.350)\n",
      "Test: [100/313]\tTime 1.490 (1.065)\tLoss 0.6045 (0.6415)\tAccuracy 71.875 (65.470)\n",
      "Test: [110/313]\tTime 0.933 (1.074)\tLoss 0.6351 (0.6402)\tAccuracy 65.625 (65.653)\n",
      "Test: [120/313]\tTime 1.830 (1.081)\tLoss 0.5795 (0.6395)\tAccuracy 75.000 (65.754)\n",
      "Test: [130/313]\tTime 0.797 (1.084)\tLoss 0.6208 (0.6402)\tAccuracy 68.750 (65.649)\n",
      "Test: [140/313]\tTime 0.761 (1.087)\tLoss 0.6042 (0.6406)\tAccuracy 71.875 (65.581)\n",
      "Test: [150/313]\tTime 0.816 (1.081)\tLoss 0.6629 (0.6398)\tAccuracy 62.500 (65.728)\n",
      "Test: [160/313]\tTime 0.874 (1.095)\tLoss 0.6419 (0.6374)\tAccuracy 65.625 (66.110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [170/313]\tTime 0.752 (1.081)\tLoss 0.6998 (0.6381)\tAccuracy 56.250 (66.009)\n",
      "Test: [180/313]\tTime 1.382 (1.080)\tLoss 0.5790 (0.6383)\tAccuracy 75.000 (65.970)\n",
      "Test: [190/313]\tTime 0.704 (1.075)\tLoss 0.7320 (0.6384)\tAccuracy 50.000 (65.936)\n",
      "Test: [200/313]\tTime 1.369 (1.077)\tLoss 0.5665 (0.6391)\tAccuracy 78.125 (65.827)\n",
      "Test: [210/313]\tTime 1.198 (1.080)\tLoss 0.6381 (0.6387)\tAccuracy 65.625 (65.906)\n",
      "Test: [220/313]\tTime 0.764 (1.082)\tLoss 0.7495 (0.6402)\tAccuracy 46.875 (65.639)\n",
      "Test: [230/313]\tTime 0.807 (1.090)\tLoss 0.6789 (0.6395)\tAccuracy 59.375 (65.747)\n",
      "Test: [240/313]\tTime 1.671 (1.096)\tLoss 0.6237 (0.6392)\tAccuracy 68.750 (65.794)\n",
      "Test: [250/313]\tTime 0.892 (1.106)\tLoss 0.5826 (0.6394)\tAccuracy 75.000 (65.762)\n",
      "Test: [260/313]\tTime 0.880 (1.103)\tLoss 0.5979 (0.6389)\tAccuracy 71.875 (65.841)\n",
      "Test: [270/313]\tTime 1.276 (1.104)\tLoss 0.5256 (0.6385)\tAccuracy 84.375 (65.890)\n",
      "Test: [280/313]\tTime 1.193 (1.105)\tLoss 0.6963 (0.6384)\tAccuracy 56.250 (65.914)\n",
      "Test: [290/313]\tTime 0.866 (1.101)\tLoss 0.7548 (0.6397)\tAccuracy 46.875 (65.689)\n",
      "Test: [300/313]\tTime 1.025 (1.111)\tLoss 0.6627 (0.6398)\tAccuracy 62.500 (65.687)\n",
      "Test: [310/313]\tTime 1.052 (1.111)\tLoss 0.6213 (0.6397)\tAccuracy 68.750 (65.695)\n",
      "Epoch: [3][0/313]\tTime 1.174 (1.174)\tData 0.784 (0.784)\tLoss 0.5926 (0.5926)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [3][10/313]\tTime 1.802 (1.600)\tData 1.322 (1.164)\tLoss 0.6940 (0.6345)\tAccuracy 56.250 (67.898)\n",
      "Epoch: [3][20/313]\tTime 1.392 (1.470)\tData 1.000 (1.069)\tLoss 0.6216 (0.6363)\tAccuracy 68.750 (66.964)\n",
      "Epoch: [3][30/313]\tTime 1.361 (1.407)\tData 0.982 (1.026)\tLoss 0.6419 (0.6389)\tAccuracy 65.625 (66.331)\n",
      "Epoch: [3][40/313]\tTime 1.033 (1.378)\tData 0.738 (1.003)\tLoss 0.6573 (0.6431)\tAccuracy 59.375 (65.625)\n",
      "Epoch: [3][50/313]\tTime 1.115 (1.440)\tData 0.801 (1.048)\tLoss 0.5315 (0.6394)\tAccuracy 81.250 (66.115)\n",
      "Epoch: [3][60/313]\tTime 2.038 (1.471)\tData 1.540 (1.072)\tLoss 0.6102 (0.6362)\tAccuracy 68.750 (66.445)\n",
      "Epoch: [3][70/313]\tTime 1.718 (1.484)\tData 1.173 (1.082)\tLoss 0.6980 (0.6382)\tAccuracy 56.250 (66.109)\n",
      "Epoch: [3][80/313]\tTime 1.560 (1.482)\tData 1.134 (1.080)\tLoss 0.7760 (0.6414)\tAccuracy 46.875 (65.741)\n",
      "Epoch: [3][90/313]\tTime 1.458 (1.476)\tData 1.074 (1.075)\tLoss 0.6446 (0.6423)\tAccuracy 68.750 (65.625)\n",
      "Epoch: [3][100/313]\tTime 1.330 (1.490)\tData 0.964 (1.085)\tLoss 0.6800 (0.6423)\tAccuracy 59.375 (65.563)\n",
      "Epoch: [3][110/313]\tTime 1.507 (1.481)\tData 1.125 (1.080)\tLoss 0.6848 (0.6429)\tAccuracy 56.250 (65.512)\n",
      "Epoch: [3][120/313]\tTime 1.932 (1.480)\tData 1.441 (1.078)\tLoss 0.5485 (0.6422)\tAccuracy 81.250 (65.677)\n",
      "Epoch: [3][130/313]\tTime 1.747 (1.470)\tData 1.321 (1.072)\tLoss 0.6224 (0.6406)\tAccuracy 68.750 (65.887)\n",
      "Epoch: [3][140/313]\tTime 1.107 (1.467)\tData 0.803 (1.070)\tLoss 0.6523 (0.6410)\tAccuracy 65.625 (65.824)\n",
      "Epoch: [3][150/313]\tTime 1.270 (1.480)\tData 0.924 (1.078)\tLoss 0.6131 (0.6395)\tAccuracy 68.750 (66.018)\n",
      "Epoch: [3][160/313]\tTime 1.133 (1.485)\tData 0.828 (1.082)\tLoss 0.6522 (0.6394)\tAccuracy 65.625 (65.994)\n",
      "Epoch: [3][170/313]\tTime 1.270 (1.481)\tData 0.914 (1.080)\tLoss 0.5888 (0.6391)\tAccuracy 71.875 (66.009)\n",
      "Epoch: [3][180/313]\tTime 1.703 (1.493)\tData 1.256 (1.088)\tLoss 0.6609 (0.6389)\tAccuracy 65.625 (66.074)\n",
      "Epoch: [3][190/313]\tTime 1.441 (1.490)\tData 1.044 (1.086)\tLoss 0.6331 (0.6399)\tAccuracy 65.625 (65.887)\n",
      "Epoch: [3][200/313]\tTime 1.785 (1.487)\tData 1.317 (1.085)\tLoss 0.5923 (0.6400)\tAccuracy 71.875 (65.889)\n",
      "Epoch: [3][210/313]\tTime 1.186 (1.498)\tData 0.841 (1.093)\tLoss 0.6162 (0.6396)\tAccuracy 68.750 (65.906)\n",
      "Epoch: [3][220/313]\tTime 1.762 (1.490)\tData 1.285 (1.087)\tLoss 0.6526 (0.6401)\tAccuracy 62.500 (65.809)\n",
      "Epoch: [3][230/313]\tTime 1.600 (1.487)\tData 1.199 (1.084)\tLoss 0.6187 (0.6387)\tAccuracy 68.750 (66.004)\n",
      "Epoch: [3][240/313]\tTime 1.773 (1.493)\tData 1.277 (1.089)\tLoss 0.6900 (0.6399)\tAccuracy 56.250 (65.820)\n",
      "Epoch: [3][250/313]\tTime 1.073 (1.491)\tData 0.788 (1.087)\tLoss 0.7160 (0.6407)\tAccuracy 53.125 (65.700)\n",
      "Epoch: [3][260/313]\tTime 1.774 (1.488)\tData 1.295 (1.085)\tLoss 0.6509 (0.6405)\tAccuracy 62.500 (65.721)\n",
      "Epoch: [3][270/313]\tTime 1.130 (1.476)\tData 0.826 (1.076)\tLoss 0.5885 (0.6406)\tAccuracy 71.875 (65.683)\n",
      "Epoch: [3][280/313]\tTime 1.461 (1.474)\tData 1.061 (1.074)\tLoss 0.6579 (0.6417)\tAccuracy 62.500 (65.503)\n",
      "Epoch: [3][290/313]\tTime 1.125 (1.474)\tData 0.811 (1.074)\tLoss 0.6005 (0.6419)\tAccuracy 68.750 (65.496)\n",
      "Epoch: [3][300/313]\tTime 1.470 (1.469)\tData 1.082 (1.070)\tLoss 0.6474 (0.6415)\tAccuracy 65.625 (65.583)\n",
      "Epoch: [3][310/313]\tTime 1.347 (1.473)\tData 0.964 (1.073)\tLoss 0.5511 (0.6408)\tAccuracy 81.250 (65.705)\n",
      "Test: [0/313]\tTime 1.026 (1.026)\tLoss 0.6849 (0.6849)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 1.196 (1.082)\tLoss 0.5783 (0.6530)\tAccuracy 75.000 (63.352)\n",
      "Test: [20/313]\tTime 1.053 (1.048)\tLoss 0.6143 (0.6520)\tAccuracy 68.750 (63.244)\n",
      "Test: [30/313]\tTime 0.689 (1.008)\tLoss 0.7013 (0.6505)\tAccuracy 56.250 (63.609)\n",
      "Test: [40/313]\tTime 1.025 (1.026)\tLoss 0.6815 (0.6498)\tAccuracy 59.375 (63.720)\n",
      "Test: [50/313]\tTime 1.482 (1.031)\tLoss 0.6363 (0.6486)\tAccuracy 65.625 (64.032)\n",
      "Test: [60/313]\tTime 1.277 (1.041)\tLoss 0.6530 (0.6445)\tAccuracy 62.500 (64.652)\n",
      "Test: [70/313]\tTime 1.307 (1.050)\tLoss 0.6284 (0.6429)\tAccuracy 65.625 (64.833)\n",
      "Test: [80/313]\tTime 0.749 (1.046)\tLoss 0.7182 (0.6409)\tAccuracy 53.125 (65.085)\n",
      "Test: [90/313]\tTime 0.793 (1.032)\tLoss 0.6352 (0.6390)\tAccuracy 65.625 (65.350)\n",
      "Test: [100/313]\tTime 1.430 (1.047)\tLoss 0.5991 (0.6379)\tAccuracy 71.875 (65.470)\n",
      "Test: [110/313]\tTime 0.747 (1.045)\tLoss 0.6181 (0.6366)\tAccuracy 65.625 (65.653)\n",
      "Test: [120/313]\tTime 2.148 (1.064)\tLoss 0.5726 (0.6356)\tAccuracy 75.000 (65.754)\n",
      "Test: [130/313]\tTime 0.810 (1.065)\tLoss 0.6209 (0.6364)\tAccuracy 68.750 (65.649)\n",
      "Test: [140/313]\tTime 0.770 (1.066)\tLoss 0.5979 (0.6368)\tAccuracy 71.875 (65.581)\n",
      "Test: [150/313]\tTime 0.852 (1.059)\tLoss 0.6621 (0.6361)\tAccuracy 62.500 (65.728)\n",
      "Test: [160/313]\tTime 0.959 (1.074)\tLoss 0.6394 (0.6337)\tAccuracy 65.625 (66.110)\n",
      "Test: [170/313]\tTime 0.872 (1.064)\tLoss 0.7014 (0.6344)\tAccuracy 56.250 (66.009)\n",
      "Test: [180/313]\tTime 1.599 (1.067)\tLoss 0.5743 (0.6345)\tAccuracy 75.000 (65.970)\n",
      "Test: [190/313]\tTime 0.648 (1.066)\tLoss 0.7400 (0.6347)\tAccuracy 50.000 (65.936)\n",
      "Test: [200/313]\tTime 1.193 (1.061)\tLoss 0.5648 (0.6356)\tAccuracy 78.125 (65.827)\n",
      "Test: [210/313]\tTime 1.223 (1.060)\tLoss 0.6304 (0.6351)\tAccuracy 65.625 (65.906)\n",
      "Test: [220/313]\tTime 0.703 (1.062)\tLoss 0.7522 (0.6368)\tAccuracy 46.875 (65.639)\n",
      "Test: [230/313]\tTime 0.855 (1.075)\tLoss 0.6721 (0.6360)\tAccuracy 59.375 (65.747)\n",
      "Test: [240/313]\tTime 1.478 (1.079)\tLoss 0.6222 (0.6357)\tAccuracy 68.750 (65.794)\n",
      "Test: [250/313]\tTime 0.869 (1.085)\tLoss 0.5761 (0.6359)\tAccuracy 75.000 (65.762)\n",
      "Test: [260/313]\tTime 0.814 (1.081)\tLoss 0.5915 (0.6355)\tAccuracy 71.875 (65.841)\n",
      "Test: [270/313]\tTime 1.320 (1.081)\tLoss 0.5185 (0.6350)\tAccuracy 84.375 (65.890)\n",
      "Test: [280/313]\tTime 1.206 (1.081)\tLoss 0.7048 (0.6350)\tAccuracy 56.250 (65.914)\n",
      "Test: [290/313]\tTime 0.803 (1.080)\tLoss 0.7497 (0.6363)\tAccuracy 46.875 (65.689)\n",
      "Test: [300/313]\tTime 0.963 (1.089)\tLoss 0.6586 (0.6363)\tAccuracy 62.500 (65.687)\n",
      "Test: [310/313]\tTime 1.057 (1.088)\tLoss 0.6183 (0.6362)\tAccuracy 68.750 (65.695)\n",
      "Epoch: [4][0/313]\tTime 1.773 (1.773)\tData 1.275 (1.275)\tLoss 0.6374 (0.6374)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [4][10/313]\tTime 2.049 (1.555)\tData 1.489 (1.125)\tLoss 0.6260 (0.6323)\tAccuracy 65.625 (66.761)\n",
      "Epoch: [4][20/313]\tTime 1.390 (1.640)\tData 1.023 (1.179)\tLoss 0.6376 (0.6274)\tAccuracy 65.625 (68.006)\n",
      "Epoch: [4][30/313]\tTime 1.328 (1.555)\tData 0.982 (1.122)\tLoss 0.5473 (0.6295)\tAccuracy 78.125 (67.540)\n",
      "Epoch: [4][40/313]\tTime 1.854 (1.555)\tData 1.406 (1.123)\tLoss 0.6672 (0.6309)\tAccuracy 65.625 (67.454)\n",
      "Epoch: [4][50/313]\tTime 1.294 (1.575)\tData 0.951 (1.139)\tLoss 0.5788 (0.6310)\tAccuracy 71.875 (67.402)\n",
      "Epoch: [4][60/313]\tTime 1.520 (1.561)\tData 1.083 (1.131)\tLoss 0.6736 (0.6298)\tAccuracy 59.375 (67.572)\n",
      "Epoch: [4][70/313]\tTime 1.387 (1.534)\tData 1.023 (1.112)\tLoss 0.5528 (0.6325)\tAccuracy 78.125 (67.254)\n",
      "Epoch: [4][80/313]\tTime 1.095 (1.530)\tData 0.790 (1.107)\tLoss 0.6082 (0.6326)\tAccuracy 68.750 (67.284)\n",
      "Epoch: [4][90/313]\tTime 1.176 (1.509)\tData 0.831 (1.091)\tLoss 0.5900 (0.6336)\tAccuracy 71.875 (67.136)\n",
      "Epoch: [4][100/313]\tTime 0.962 (1.504)\tData 0.698 (1.088)\tLoss 0.6037 (0.6305)\tAccuracy 71.875 (67.543)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][110/313]\tTime 1.205 (1.478)\tData 0.870 (1.069)\tLoss 0.6298 (0.6309)\tAccuracy 68.750 (67.427)\n",
      "Epoch: [4][120/313]\tTime 1.217 (1.479)\tData 0.859 (1.070)\tLoss 0.7384 (0.6321)\tAccuracy 53.125 (67.252)\n",
      "Epoch: [4][130/313]\tTime 1.085 (1.480)\tData 0.790 (1.071)\tLoss 0.5786 (0.6335)\tAccuracy 75.000 (67.032)\n",
      "Epoch: [4][140/313]\tTime 1.257 (1.471)\tData 0.912 (1.064)\tLoss 0.5356 (0.6332)\tAccuracy 81.250 (67.043)\n",
      "Epoch: [4][150/313]\tTime 1.198 (1.454)\tData 0.891 (1.052)\tLoss 0.6136 (0.6342)\tAccuracy 68.750 (66.929)\n",
      "Epoch: [4][160/313]\tTime 1.852 (1.446)\tData 1.304 (1.046)\tLoss 0.6777 (0.6342)\tAccuracy 59.375 (66.945)\n",
      "Epoch: [4][170/313]\tTime 1.083 (1.438)\tData 0.800 (1.040)\tLoss 0.6258 (0.6334)\tAccuracy 65.625 (67.032)\n",
      "Epoch: [4][180/313]\tTime 1.845 (1.434)\tData 1.358 (1.037)\tLoss 0.6692 (0.6347)\tAccuracy 65.625 (66.851)\n",
      "Epoch: [4][190/313]\tTime 0.933 (1.429)\tData 0.677 (1.034)\tLoss 0.6642 (0.6359)\tAccuracy 65.625 (66.721)\n",
      "Epoch: [4][200/313]\tTime 1.044 (1.429)\tData 0.780 (1.033)\tLoss 0.7048 (0.6374)\tAccuracy 56.250 (66.465)\n",
      "Epoch: [4][210/313]\tTime 1.318 (1.428)\tData 0.922 (1.033)\tLoss 0.7379 (0.6384)\tAccuracy 50.000 (66.306)\n",
      "Epoch: [4][220/313]\tTime 1.704 (1.428)\tData 1.256 (1.032)\tLoss 0.6516 (0.6390)\tAccuracy 62.500 (66.205)\n",
      "Epoch: [4][230/313]\tTime 1.266 (1.429)\tData 0.890 (1.033)\tLoss 0.6267 (0.6386)\tAccuracy 65.625 (66.234)\n",
      "Epoch: [4][240/313]\tTime 1.838 (1.429)\tData 1.330 (1.033)\tLoss 0.6331 (0.6386)\tAccuracy 65.625 (66.170)\n",
      "Epoch: [4][250/313]\tTime 1.859 (1.427)\tData 1.362 (1.032)\tLoss 0.6513 (0.6390)\tAccuracy 62.500 (66.098)\n",
      "Epoch: [4][260/313]\tTime 1.340 (1.419)\tData 0.934 (1.025)\tLoss 0.6565 (0.6394)\tAccuracy 62.500 (65.984)\n",
      "Epoch: [4][270/313]\tTime 2.094 (1.414)\tData 1.617 (1.022)\tLoss 0.6755 (0.6392)\tAccuracy 59.375 (65.994)\n",
      "Epoch: [4][280/313]\tTime 1.187 (1.409)\tData 0.862 (1.018)\tLoss 0.6788 (0.6401)\tAccuracy 59.375 (65.847)\n",
      "Epoch: [4][290/313]\tTime 1.425 (1.406)\tData 1.061 (1.016)\tLoss 0.6157 (0.6398)\tAccuracy 68.750 (65.883)\n",
      "Epoch: [4][300/313]\tTime 2.122 (1.407)\tData 1.562 (1.016)\tLoss 0.6734 (0.6402)\tAccuracy 59.375 (65.822)\n",
      "Epoch: [4][310/313]\tTime 1.318 (1.405)\tData 0.967 (1.015)\tLoss 0.7611 (0.6408)\tAccuracy 46.875 (65.705)\n",
      "Test: [0/313]\tTime 0.935 (0.935)\tLoss 0.6842 (0.6842)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 1.219 (0.998)\tLoss 0.5769 (0.6512)\tAccuracy 75.000 (63.352)\n",
      "Test: [20/313]\tTime 1.077 (1.019)\tLoss 0.6142 (0.6510)\tAccuracy 68.750 (63.244)\n",
      "Test: [30/313]\tTime 0.758 (1.004)\tLoss 0.7022 (0.6489)\tAccuracy 56.250 (63.609)\n",
      "Test: [40/313]\tTime 1.023 (1.024)\tLoss 0.6782 (0.6482)\tAccuracy 59.375 (63.720)\n",
      "Test: [50/313]\tTime 1.440 (1.033)\tLoss 0.6319 (0.6466)\tAccuracy 65.625 (64.032)\n",
      "Test: [60/313]\tTime 1.815 (1.056)\tLoss 0.6564 (0.6429)\tAccuracy 62.500 (64.652)\n",
      "Test: [70/313]\tTime 1.326 (1.070)\tLoss 0.6252 (0.6410)\tAccuracy 65.625 (64.833)\n",
      "Test: [80/313]\tTime 0.719 (1.065)\tLoss 0.7132 (0.6391)\tAccuracy 53.125 (65.085)\n",
      "Test: [90/313]\tTime 0.690 (1.049)\tLoss 0.6350 (0.6374)\tAccuracy 65.625 (65.350)\n",
      "Test: [100/313]\tTime 1.287 (1.057)\tLoss 0.5981 (0.6364)\tAccuracy 71.875 (65.470)\n",
      "Test: [110/313]\tTime 0.789 (1.051)\tLoss 0.6226 (0.6352)\tAccuracy 65.625 (65.653)\n",
      "Test: [120/313]\tTime 2.109 (1.052)\tLoss 0.5710 (0.6342)\tAccuracy 75.000 (65.780)\n",
      "Test: [130/313]\tTime 0.792 (1.050)\tLoss 0.6214 (0.6350)\tAccuracy 68.750 (65.673)\n",
      "Test: [140/313]\tTime 0.787 (1.053)\tLoss 0.5986 (0.6355)\tAccuracy 71.875 (65.603)\n",
      "Test: [150/313]\tTime 0.792 (1.047)\tLoss 0.6537 (0.6348)\tAccuracy 62.500 (65.749)\n",
      "Test: [160/313]\tTime 0.865 (1.064)\tLoss 0.6380 (0.6324)\tAccuracy 65.625 (66.130)\n",
      "Test: [170/313]\tTime 0.826 (1.057)\tLoss 0.7015 (0.6332)\tAccuracy 56.250 (66.027)\n",
      "Test: [180/313]\tTime 1.544 (1.067)\tLoss 0.5723 (0.6333)\tAccuracy 75.000 (66.005)\n",
      "Test: [190/313]\tTime 0.786 (1.068)\tLoss 0.7367 (0.6335)\tAccuracy 50.000 (65.969)\n",
      "Test: [200/313]\tTime 1.121 (1.061)\tLoss 0.5642 (0.6343)\tAccuracy 78.125 (65.858)\n",
      "Test: [210/313]\tTime 1.280 (1.063)\tLoss 0.6334 (0.6338)\tAccuracy 65.625 (65.951)\n",
      "Test: [220/313]\tTime 0.749 (1.063)\tLoss 0.7473 (0.6354)\tAccuracy 46.875 (65.682)\n",
      "Test: [230/313]\tTime 0.827 (1.074)\tLoss 0.6709 (0.6345)\tAccuracy 59.375 (65.787)\n",
      "Test: [240/313]\tTime 1.521 (1.079)\tLoss 0.6170 (0.6343)\tAccuracy 68.750 (65.832)\n",
      "Test: [250/313]\tTime 0.829 (1.086)\tLoss 0.5743 (0.6344)\tAccuracy 75.000 (65.812)\n",
      "Test: [260/313]\tTime 0.821 (1.083)\tLoss 0.5937 (0.6341)\tAccuracy 71.875 (65.888)\n",
      "Test: [270/313]\tTime 1.212 (1.083)\tLoss 0.5164 (0.6337)\tAccuracy 84.375 (65.936)\n",
      "Test: [280/313]\tTime 1.483 (1.086)\tLoss 0.7047 (0.6337)\tAccuracy 56.250 (65.959)\n",
      "Test: [290/313]\tTime 0.755 (1.081)\tLoss 0.7519 (0.6350)\tAccuracy 46.875 (65.732)\n",
      "Test: [300/313]\tTime 0.951 (1.086)\tLoss 0.6661 (0.6351)\tAccuracy 62.500 (65.739)\n",
      "Test: [310/313]\tTime 1.054 (1.086)\tLoss 0.6197 (0.6350)\tAccuracy 68.750 (65.746)\n",
      "Epoch: [5][0/313]\tTime 1.920 (1.920)\tData 1.426 (1.426)\tLoss 0.6892 (0.6892)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [5][10/313]\tTime 1.477 (1.380)\tData 1.083 (0.987)\tLoss 0.6558 (0.6380)\tAccuracy 59.375 (65.909)\n",
      "Epoch: [5][20/313]\tTime 2.101 (1.498)\tData 1.647 (1.082)\tLoss 0.6956 (0.6364)\tAccuracy 56.250 (66.220)\n",
      "Epoch: [5][30/313]\tTime 1.289 (1.486)\tData 0.896 (1.066)\tLoss 0.6693 (0.6436)\tAccuracy 62.500 (65.323)\n",
      "Epoch: [5][40/313]\tTime 1.973 (1.520)\tData 1.472 (1.092)\tLoss 0.7043 (0.6391)\tAccuracy 56.250 (66.082)\n",
      "Epoch: [5][50/313]\tTime 1.704 (1.499)\tData 1.165 (1.075)\tLoss 0.5637 (0.6435)\tAccuracy 78.125 (65.441)\n",
      "Epoch: [5][60/313]\tTime 1.919 (1.535)\tData 1.478 (1.108)\tLoss 0.5775 (0.6449)\tAccuracy 75.000 (65.215)\n",
      "Epoch: [5][70/313]\tTime 1.434 (1.555)\tData 1.047 (1.123)\tLoss 0.6473 (0.6455)\tAccuracy 65.625 (65.053)\n",
      "Epoch: [5][80/313]\tTime 1.376 (1.536)\tData 0.994 (1.110)\tLoss 0.6700 (0.6442)\tAccuracy 59.375 (65.239)\n",
      "Epoch: [5][90/313]\tTime 1.579 (1.556)\tData 1.115 (1.125)\tLoss 0.7573 (0.6465)\tAccuracy 50.000 (64.904)\n",
      "Epoch: [5][100/313]\tTime 1.729 (1.561)\tData 1.208 (1.129)\tLoss 0.6117 (0.6490)\tAccuracy 68.750 (64.480)\n",
      "Epoch: [5][110/313]\tTime 1.942 (1.560)\tData 1.380 (1.128)\tLoss 0.6488 (0.6479)\tAccuracy 62.500 (64.611)\n",
      "Epoch: [5][120/313]\tTime 2.118 (1.570)\tData 1.486 (1.135)\tLoss 0.6349 (0.6477)\tAccuracy 65.625 (64.644)\n",
      "Epoch: [5][130/313]\tTime 1.787 (1.568)\tData 1.331 (1.132)\tLoss 0.5847 (0.6459)\tAccuracy 71.875 (64.909)\n",
      "Epoch: [5][140/313]\tTime 1.443 (1.579)\tData 1.042 (1.142)\tLoss 0.6602 (0.6466)\tAccuracy 65.625 (64.916)\n",
      "Epoch: [5][150/313]\tTime 1.366 (1.567)\tData 0.979 (1.132)\tLoss 0.6426 (0.6475)\tAccuracy 65.625 (64.756)\n",
      "Epoch: [5][160/313]\tTime 1.725 (1.570)\tData 1.302 (1.136)\tLoss 0.6372 (0.6476)\tAccuracy 65.625 (64.693)\n",
      "Epoch: [5][170/313]\tTime 1.742 (1.576)\tData 1.056 (1.140)\tLoss 0.5887 (0.6451)\tAccuracy 71.875 (65.040)\n",
      "Epoch: [5][180/313]\tTime 1.107 (1.556)\tData 0.804 (1.126)\tLoss 0.7406 (0.6447)\tAccuracy 50.000 (65.159)\n",
      "Epoch: [5][190/313]\tTime 1.088 (1.535)\tData 0.778 (1.110)\tLoss 0.6297 (0.6438)\tAccuracy 65.625 (65.265)\n",
      "Epoch: [5][200/313]\tTime 0.955 (1.549)\tData 0.684 (1.121)\tLoss 0.5970 (0.6439)\tAccuracy 68.750 (65.236)\n",
      "Epoch: [5][210/313]\tTime 1.347 (1.536)\tData 0.965 (1.112)\tLoss 0.6789 (0.6432)\tAccuracy 56.250 (65.329)\n",
      "Epoch: [5][220/313]\tTime 2.315 (1.556)\tData 1.720 (1.128)\tLoss 0.6132 (0.6430)\tAccuracy 71.875 (65.314)\n",
      "Epoch: [5][230/313]\tTime 1.098 (1.559)\tData 0.791 (1.131)\tLoss 0.5748 (0.6433)\tAccuracy 75.000 (65.273)\n",
      "Epoch: [5][240/313]\tTime 1.460 (1.547)\tData 1.005 (1.122)\tLoss 0.5749 (0.6423)\tAccuracy 75.000 (65.379)\n",
      "Epoch: [5][250/313]\tTime 1.089 (1.536)\tData 0.760 (1.114)\tLoss 0.6290 (0.6414)\tAccuracy 68.750 (65.550)\n",
      "Epoch: [5][260/313]\tTime 1.433 (1.539)\tData 1.039 (1.117)\tLoss 0.6448 (0.6416)\tAccuracy 62.500 (65.493)\n",
      "Epoch: [5][270/313]\tTime 1.592 (1.533)\tData 1.152 (1.113)\tLoss 0.6599 (0.6406)\tAccuracy 62.500 (65.613)\n",
      "Epoch: [5][280/313]\tTime 3.064 (1.529)\tData 2.065 (1.110)\tLoss 0.5818 (0.6408)\tAccuracy 75.000 (65.603)\n",
      "Epoch: [5][290/313]\tTime 1.741 (1.524)\tData 1.368 (1.107)\tLoss 0.5933 (0.6408)\tAccuracy 68.750 (65.614)\n",
      "Epoch: [5][300/313]\tTime 2.698 (1.533)\tData 2.026 (1.115)\tLoss 0.5960 (0.6402)\tAccuracy 71.875 (65.687)\n",
      "Epoch: [5][310/313]\tTime 1.235 (1.532)\tData 0.917 (1.115)\tLoss 0.5875 (0.6401)\tAccuracy 71.875 (65.695)\n",
      "Test: [0/313]\tTime 0.959 (0.959)\tLoss 0.6827 (0.6827)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 1.277 (1.101)\tLoss 0.5765 (0.6499)\tAccuracy 75.000 (63.352)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [20/313]\tTime 1.142 (1.042)\tLoss 0.6073 (0.6488)\tAccuracy 68.750 (63.244)\n",
      "Test: [30/313]\tTime 0.649 (0.999)\tLoss 0.7011 (0.6478)\tAccuracy 56.250 (63.609)\n",
      "Test: [40/313]\tTime 0.986 (1.043)\tLoss 0.6818 (0.6468)\tAccuracy 59.375 (63.720)\n",
      "Test: [50/313]\tTime 1.627 (1.044)\tLoss 0.6343 (0.6454)\tAccuracy 65.625 (64.032)\n",
      "Test: [60/313]\tTime 1.408 (1.077)\tLoss 0.6523 (0.6410)\tAccuracy 62.500 (64.652)\n",
      "Test: [70/313]\tTime 1.139 (1.080)\tLoss 0.6237 (0.6391)\tAccuracy 65.625 (64.833)\n",
      "Test: [80/313]\tTime 1.382 (1.082)\tLoss 0.7189 (0.6370)\tAccuracy 53.125 (65.123)\n",
      "Test: [90/313]\tTime 0.649 (1.065)\tLoss 0.6312 (0.6349)\tAccuracy 65.625 (65.385)\n",
      "Test: [100/313]\tTime 1.883 (1.086)\tLoss 0.5911 (0.6340)\tAccuracy 71.875 (65.501)\n",
      "Test: [110/313]\tTime 0.977 (1.115)\tLoss 0.6107 (0.6325)\tAccuracy 65.625 (65.681)\n",
      "Test: [120/313]\tTime 2.421 (1.136)\tLoss 0.5643 (0.6317)\tAccuracy 75.000 (65.780)\n",
      "Test: [130/313]\tTime 0.736 (1.150)\tLoss 0.6134 (0.6325)\tAccuracy 68.750 (65.673)\n",
      "Test: [140/313]\tTime 0.888 (1.152)\tLoss 0.5983 (0.6328)\tAccuracy 71.875 (65.603)\n",
      "Test: [150/313]\tTime 0.948 (1.146)\tLoss 0.6590 (0.6321)\tAccuracy 62.500 (65.749)\n",
      "Test: [160/313]\tTime 0.891 (1.159)\tLoss 0.6368 (0.6298)\tAccuracy 65.625 (66.130)\n",
      "Test: [170/313]\tTime 0.812 (1.140)\tLoss 0.7028 (0.6306)\tAccuracy 56.250 (66.027)\n",
      "Test: [180/313]\tTime 1.646 (1.149)\tLoss 0.5636 (0.6308)\tAccuracy 75.000 (66.005)\n",
      "Test: [190/313]\tTime 0.689 (1.145)\tLoss 0.7437 (0.6310)\tAccuracy 50.000 (65.969)\n",
      "Test: [200/313]\tTime 1.120 (1.133)\tLoss 0.5609 (0.6319)\tAccuracy 78.125 (65.858)\n",
      "Test: [210/313]\tTime 1.187 (1.133)\tLoss 0.6283 (0.6314)\tAccuracy 65.625 (65.951)\n",
      "Test: [220/313]\tTime 0.956 (1.138)\tLoss 0.7440 (0.6330)\tAccuracy 46.875 (65.696)\n",
      "Test: [230/313]\tTime 1.186 (1.151)\tLoss 0.6729 (0.6321)\tAccuracy 59.375 (65.801)\n",
      "Test: [240/313]\tTime 1.668 (1.169)\tLoss 0.6113 (0.6318)\tAccuracy 68.750 (65.845)\n",
      "Test: [250/313]\tTime 0.898 (1.173)\tLoss 0.5747 (0.6320)\tAccuracy 75.000 (65.812)\n",
      "Test: [260/313]\tTime 0.959 (1.168)\tLoss 0.5859 (0.6317)\tAccuracy 71.875 (65.888)\n",
      "Test: [270/313]\tTime 1.458 (1.166)\tLoss 0.5108 (0.6312)\tAccuracy 84.375 (65.936)\n",
      "Test: [280/313]\tTime 1.565 (1.171)\tLoss 0.7001 (0.6312)\tAccuracy 56.250 (65.959)\n",
      "Test: [290/313]\tTime 0.951 (1.166)\tLoss 0.7527 (0.6326)\tAccuracy 46.875 (65.732)\n",
      "Test: [300/313]\tTime 1.112 (1.175)\tLoss 0.6529 (0.6326)\tAccuracy 62.500 (65.739)\n",
      "Test: [310/313]\tTime 0.870 (1.173)\tLoss 0.6157 (0.6326)\tAccuracy 68.750 (65.746)\n",
      "Epoch: [6][0/313]\tTime 1.525 (1.525)\tData 1.067 (1.067)\tLoss 0.6720 (0.6720)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [6][10/313]\tTime 1.287 (1.466)\tData 0.938 (1.047)\tLoss 0.6844 (0.6355)\tAccuracy 59.375 (66.193)\n",
      "Epoch: [6][20/313]\tTime 1.059 (1.487)\tData 0.781 (1.044)\tLoss 0.6874 (0.6352)\tAccuracy 56.250 (65.923)\n",
      "Epoch: [6][30/313]\tTime 1.391 (1.422)\tData 0.997 (1.004)\tLoss 0.6256 (0.6416)\tAccuracy 65.625 (64.819)\n",
      "Epoch: [6][40/313]\tTime 0.902 (1.401)\tData 0.662 (0.991)\tLoss 0.6054 (0.6373)\tAccuracy 71.875 (65.854)\n",
      "Epoch: [6][50/313]\tTime 1.372 (1.366)\tData 0.948 (0.970)\tLoss 0.6396 (0.6351)\tAccuracy 62.500 (65.993)\n",
      "Epoch: [6][60/313]\tTime 1.337 (1.387)\tData 0.985 (0.988)\tLoss 0.6061 (0.6352)\tAccuracy 71.875 (66.240)\n",
      "Epoch: [6][70/313]\tTime 1.194 (1.361)\tData 0.835 (0.968)\tLoss 0.6612 (0.6349)\tAccuracy 65.625 (66.373)\n",
      "Epoch: [6][80/313]\tTime 1.125 (1.352)\tData 0.824 (0.962)\tLoss 0.5923 (0.6384)\tAccuracy 71.875 (65.779)\n",
      "Epoch: [6][90/313]\tTime 1.531 (1.371)\tData 1.094 (0.976)\tLoss 0.6493 (0.6381)\tAccuracy 62.500 (65.762)\n",
      "Epoch: [6][100/313]\tTime 1.491 (1.375)\tData 1.047 (0.979)\tLoss 0.5362 (0.6373)\tAccuracy 81.250 (65.780)\n",
      "Epoch: [6][110/313]\tTime 1.112 (1.377)\tData 0.790 (0.981)\tLoss 0.7497 (0.6395)\tAccuracy 53.125 (65.456)\n",
      "Epoch: [6][120/313]\tTime 1.746 (1.371)\tData 1.243 (0.978)\tLoss 0.6825 (0.6419)\tAccuracy 65.625 (65.186)\n",
      "Epoch: [6][130/313]\tTime 5.134 (1.399)\tData 3.410 (0.995)\tLoss 0.5371 (0.6410)\tAccuracy 81.250 (65.291)\n",
      "Epoch: [6][140/313]\tTime 1.406 (1.408)\tData 0.976 (1.002)\tLoss 0.6882 (0.6412)\tAccuracy 59.375 (65.270)\n",
      "Epoch: [6][150/313]\tTime 1.353 (1.411)\tData 0.991 (1.005)\tLoss 0.5742 (0.6406)\tAccuracy 75.000 (65.397)\n",
      "Epoch: [6][160/313]\tTime 1.193 (1.396)\tData 0.874 (0.996)\tLoss 0.6822 (0.6408)\tAccuracy 75.000 (65.411)\n",
      "Epoch: [6][170/313]\tTime 1.437 (1.404)\tData 1.064 (1.003)\tLoss 0.5421 (0.6394)\tAccuracy 81.250 (65.570)\n",
      "Epoch: [6][180/313]\tTime 2.318 (1.435)\tData 1.397 (1.025)\tLoss 0.5921 (0.6394)\tAccuracy 75.000 (65.539)\n",
      "Epoch: [6][190/313]\tTime 1.414 (1.448)\tData 0.993 (1.035)\tLoss 0.6585 (0.6387)\tAccuracy 62.500 (65.625)\n",
      "Epoch: [6][200/313]\tTime 1.256 (1.444)\tData 0.960 (1.033)\tLoss 0.6320 (0.6398)\tAccuracy 62.500 (65.407)\n",
      "Epoch: [6][210/313]\tTime 1.210 (1.445)\tData 0.904 (1.035)\tLoss 0.6402 (0.6397)\tAccuracy 65.625 (65.418)\n",
      "Epoch: [6][220/313]\tTime 1.836 (1.466)\tData 1.401 (1.052)\tLoss 0.5908 (0.6396)\tAccuracy 75.000 (65.484)\n",
      "Epoch: [6][230/313]\tTime 1.455 (1.463)\tData 1.086 (1.050)\tLoss 0.6409 (0.6395)\tAccuracy 62.500 (65.530)\n",
      "Epoch: [6][240/313]\tTime 1.493 (1.472)\tData 1.060 (1.057)\tLoss 0.7064 (0.6409)\tAccuracy 56.250 (65.301)\n",
      "Epoch: [6][250/313]\tTime 1.480 (1.478)\tData 1.065 (1.062)\tLoss 0.6301 (0.6395)\tAccuracy 68.750 (65.513)\n",
      "Epoch: [6][260/313]\tTime 1.681 (1.490)\tData 1.251 (1.071)\tLoss 0.5660 (0.6387)\tAccuracy 71.875 (65.577)\n",
      "Epoch: [6][270/313]\tTime 1.113 (1.494)\tData 0.798 (1.075)\tLoss 0.6704 (0.6393)\tAccuracy 62.500 (65.487)\n",
      "Epoch: [6][280/313]\tTime 1.528 (1.498)\tData 1.109 (1.078)\tLoss 0.6670 (0.6384)\tAccuracy 59.375 (65.647)\n",
      "Epoch: [6][290/313]\tTime 1.478 (1.500)\tData 1.136 (1.080)\tLoss 0.6277 (0.6393)\tAccuracy 65.625 (65.528)\n",
      "Epoch: [6][300/313]\tTime 1.070 (1.500)\tData 0.771 (1.080)\tLoss 0.6187 (0.6389)\tAccuracy 65.625 (65.594)\n",
      "Epoch: [6][310/313]\tTime 1.070 (1.503)\tData 0.789 (1.084)\tLoss 0.5426 (0.6388)\tAccuracy 81.250 (65.625)\n",
      "Test: [0/313]\tTime 0.962 (0.962)\tLoss 0.6774 (0.6774)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 1.218 (1.136)\tLoss 0.5769 (0.6484)\tAccuracy 75.000 (63.352)\n",
      "Test: [20/313]\tTime 1.110 (1.135)\tLoss 0.6066 (0.6465)\tAccuracy 68.750 (63.244)\n",
      "Test: [30/313]\tTime 0.741 (1.094)\tLoss 0.7016 (0.6465)\tAccuracy 56.250 (63.609)\n",
      "Test: [40/313]\tTime 1.115 (1.114)\tLoss 0.6915 (0.6460)\tAccuracy 59.375 (63.720)\n",
      "Test: [50/313]\tTime 1.708 (1.120)\tLoss 0.6338 (0.6446)\tAccuracy 65.625 (64.032)\n",
      "Test: [60/313]\tTime 1.277 (1.120)\tLoss 0.6474 (0.6400)\tAccuracy 62.500 (64.652)\n",
      "Test: [70/313]\tTime 1.440 (1.129)\tLoss 0.6262 (0.6383)\tAccuracy 65.625 (64.833)\n",
      "Test: [80/313]\tTime 1.106 (1.147)\tLoss 0.7339 (0.6363)\tAccuracy 53.125 (65.123)\n",
      "Test: [90/313]\tTime 0.871 (1.137)\tLoss 0.6269 (0.6339)\tAccuracy 65.625 (65.385)\n",
      "Test: [100/313]\tTime 1.467 (1.158)\tLoss 0.5913 (0.6330)\tAccuracy 71.875 (65.501)\n",
      "Test: [110/313]\tTime 0.901 (1.158)\tLoss 0.6048 (0.6316)\tAccuracy 65.625 (65.681)\n",
      "Test: [120/313]\tTime 1.904 (1.159)\tLoss 0.5611 (0.6310)\tAccuracy 75.000 (65.780)\n",
      "Test: [130/313]\tTime 0.860 (1.158)\tLoss 0.6115 (0.6318)\tAccuracy 68.750 (65.673)\n",
      "Test: [140/313]\tTime 0.879 (1.163)\tLoss 0.5980 (0.6322)\tAccuracy 71.875 (65.603)\n",
      "Test: [150/313]\tTime 0.840 (1.155)\tLoss 0.6577 (0.6313)\tAccuracy 62.500 (65.749)\n",
      "Test: [160/313]\tTime 1.083 (1.174)\tLoss 0.6349 (0.6291)\tAccuracy 65.625 (66.130)\n",
      "Test: [170/313]\tTime 0.877 (1.164)\tLoss 0.7049 (0.6300)\tAccuracy 56.250 (66.027)\n",
      "Test: [180/313]\tTime 1.816 (1.171)\tLoss 0.5626 (0.6300)\tAccuracy 75.000 (66.005)\n",
      "Test: [190/313]\tTime 0.781 (1.172)\tLoss 0.7463 (0.6304)\tAccuracy 50.000 (65.969)\n",
      "Test: [200/313]\tTime 1.167 (1.163)\tLoss 0.5626 (0.6313)\tAccuracy 78.125 (65.858)\n",
      "Test: [210/313]\tTime 1.406 (1.165)\tLoss 0.6272 (0.6307)\tAccuracy 65.625 (65.951)\n",
      "Test: [220/313]\tTime 0.778 (1.167)\tLoss 0.7555 (0.6325)\tAccuracy 46.875 (65.682)\n",
      "Test: [230/313]\tTime 0.950 (1.174)\tLoss 0.6731 (0.6317)\tAccuracy 59.375 (65.787)\n",
      "Test: [240/313]\tTime 1.674 (1.179)\tLoss 0.6202 (0.6314)\tAccuracy 68.750 (65.832)\n",
      "Test: [250/313]\tTime 0.950 (1.189)\tLoss 0.5703 (0.6316)\tAccuracy 75.000 (65.799)\n",
      "Test: [260/313]\tTime 1.033 (1.185)\tLoss 0.5799 (0.6312)\tAccuracy 71.875 (65.876)\n",
      "Test: [270/313]\tTime 1.315 (1.190)\tLoss 0.5092 (0.6307)\tAccuracy 84.375 (65.925)\n",
      "Test: [280/313]\tTime 1.518 (1.194)\tLoss 0.7046 (0.6305)\tAccuracy 56.250 (65.948)\n",
      "Test: [290/313]\tTime 0.837 (1.195)\tLoss 0.7532 (0.6319)\tAccuracy 46.875 (65.722)\n",
      "Test: [300/313]\tTime 1.045 (1.201)\tLoss 0.6543 (0.6321)\tAccuracy 62.500 (65.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [310/313]\tTime 1.062 (1.200)\tLoss 0.6086 (0.6320)\tAccuracy 68.750 (65.736)\n",
      "Epoch: [7][0/313]\tTime 1.640 (1.640)\tData 1.174 (1.174)\tLoss 0.6419 (0.6419)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [7][10/313]\tTime 2.075 (1.571)\tData 1.526 (1.136)\tLoss 0.6557 (0.6392)\tAccuracy 65.625 (65.341)\n",
      "Epoch: [7][20/313]\tTime 1.588 (1.577)\tData 1.185 (1.147)\tLoss 0.7078 (0.6497)\tAccuracy 56.250 (63.988)\n",
      "Epoch: [7][30/313]\tTime 1.237 (1.559)\tData 0.860 (1.135)\tLoss 0.6304 (0.6506)\tAccuracy 68.750 (63.810)\n",
      "Epoch: [7][40/313]\tTime 1.672 (1.553)\tData 1.204 (1.130)\tLoss 0.6492 (0.6578)\tAccuracy 65.625 (62.957)\n",
      "Epoch: [7][50/313]\tTime 2.121 (1.552)\tData 1.541 (1.130)\tLoss 0.5770 (0.6488)\tAccuracy 71.875 (64.032)\n",
      "Epoch: [7][60/313]\tTime 1.377 (1.529)\tData 1.021 (1.114)\tLoss 0.6755 (0.6465)\tAccuracy 59.375 (64.242)\n",
      "Epoch: [7][70/313]\tTime 1.937 (1.519)\tData 1.409 (1.105)\tLoss 0.6972 (0.6452)\tAccuracy 56.250 (64.481)\n",
      "Epoch: [7][80/313]\tTime 1.156 (1.542)\tData 0.813 (1.123)\tLoss 0.6390 (0.6438)\tAccuracy 65.625 (64.660)\n",
      "Epoch: [7][90/313]\tTime 1.339 (1.545)\tData 0.942 (1.124)\tLoss 0.6584 (0.6433)\tAccuracy 62.500 (64.766)\n",
      "Epoch: [7][100/313]\tTime 1.664 (1.513)\tData 1.229 (1.099)\tLoss 0.6402 (0.6432)\tAccuracy 68.750 (64.790)\n",
      "Epoch: [7][110/313]\tTime 1.354 (1.487)\tData 0.947 (1.078)\tLoss 0.6154 (0.6411)\tAccuracy 68.750 (65.062)\n",
      "Epoch: [7][120/313]\tTime 2.991 (1.491)\tData 2.127 (1.078)\tLoss 0.7029 (0.6408)\tAccuracy 56.250 (65.031)\n",
      "Epoch: [7][130/313]\tTime 2.432 (1.486)\tData 1.846 (1.075)\tLoss 0.7214 (0.6434)\tAccuracy 56.250 (64.623)\n",
      "Epoch: [7][140/313]\tTime 1.081 (1.496)\tData 0.788 (1.081)\tLoss 0.5755 (0.6421)\tAccuracy 71.875 (64.849)\n",
      "Epoch: [7][150/313]\tTime 0.997 (1.476)\tData 0.719 (1.066)\tLoss 0.5999 (0.6423)\tAccuracy 71.875 (64.839)\n",
      "Epoch: [7][160/313]\tTime 2.238 (1.476)\tData 1.618 (1.065)\tLoss 0.6553 (0.6417)\tAccuracy 65.625 (64.946)\n",
      "Epoch: [7][170/313]\tTime 1.139 (1.466)\tData 0.818 (1.057)\tLoss 0.6481 (0.6437)\tAccuracy 65.625 (64.675)\n",
      "Epoch: [7][180/313]\tTime 1.462 (1.460)\tData 1.049 (1.053)\tLoss 0.5963 (0.6445)\tAccuracy 75.000 (64.572)\n",
      "Epoch: [7][190/313]\tTime 1.021 (1.450)\tData 0.717 (1.045)\tLoss 0.7673 (0.6451)\tAccuracy 43.750 (64.480)\n",
      "Epoch: [7][200/313]\tTime 0.990 (1.435)\tData 0.676 (1.033)\tLoss 0.6036 (0.6449)\tAccuracy 68.750 (64.506)\n",
      "Epoch: [7][210/313]\tTime 1.049 (1.429)\tData 0.753 (1.028)\tLoss 0.5834 (0.6432)\tAccuracy 75.000 (64.796)\n",
      "Epoch: [7][220/313]\tTime 1.729 (1.422)\tData 1.366 (1.024)\tLoss 0.6108 (0.6430)\tAccuracy 68.750 (64.847)\n",
      "Epoch: [7][230/313]\tTime 1.102 (1.423)\tData 0.776 (1.024)\tLoss 0.6293 (0.6422)\tAccuracy 65.625 (65.003)\n",
      "Epoch: [7][240/313]\tTime 1.426 (1.416)\tData 1.029 (1.019)\tLoss 0.5903 (0.6411)\tAccuracy 71.875 (65.158)\n",
      "Epoch: [7][250/313]\tTime 1.212 (1.410)\tData 0.846 (1.014)\tLoss 0.5119 (0.6395)\tAccuracy 81.250 (65.351)\n",
      "Epoch: [7][260/313]\tTime 1.679 (1.407)\tData 1.186 (1.012)\tLoss 0.5906 (0.6392)\tAccuracy 68.750 (65.374)\n",
      "Epoch: [7][270/313]\tTime 1.272 (1.403)\tData 0.910 (1.009)\tLoss 0.6434 (0.6393)\tAccuracy 62.500 (65.314)\n",
      "Epoch: [7][280/313]\tTime 0.927 (1.395)\tData 0.652 (1.002)\tLoss 0.5652 (0.6387)\tAccuracy 75.000 (65.403)\n",
      "Epoch: [7][290/313]\tTime 0.877 (1.390)\tData 0.618 (0.999)\tLoss 0.6056 (0.6381)\tAccuracy 65.625 (65.507)\n",
      "Epoch: [7][300/313]\tTime 1.365 (1.389)\tData 0.967 (0.998)\tLoss 0.7040 (0.6374)\tAccuracy 59.375 (65.594)\n",
      "Epoch: [7][310/313]\tTime 1.063 (1.386)\tData 0.775 (0.997)\tLoss 0.7190 (0.6376)\tAccuracy 56.250 (65.655)\n",
      "Test: [0/313]\tTime 0.867 (0.867)\tLoss 0.6828 (0.6828)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 1.120 (0.938)\tLoss 0.5721 (0.6422)\tAccuracy 75.000 (63.636)\n",
      "Test: [20/313]\tTime 0.919 (0.910)\tLoss 0.6038 (0.6430)\tAccuracy 68.750 (63.393)\n",
      "Test: [30/313]\tTime 0.655 (0.886)\tLoss 0.7031 (0.6422)\tAccuracy 56.250 (63.911)\n",
      "Test: [40/313]\tTime 0.888 (0.909)\tLoss 0.6836 (0.6413)\tAccuracy 59.375 (64.101)\n",
      "Test: [50/313]\tTime 1.297 (0.912)\tLoss 0.6233 (0.6394)\tAccuracy 65.625 (64.400)\n",
      "Test: [60/313]\tTime 1.061 (0.915)\tLoss 0.6463 (0.6353)\tAccuracy 62.500 (65.061)\n",
      "Test: [70/313]\tTime 1.135 (0.922)\tLoss 0.6195 (0.6334)\tAccuracy 65.625 (65.229)\n",
      "Test: [80/313]\tTime 0.639 (0.919)\tLoss 0.7222 (0.6313)\tAccuracy 53.125 (65.509)\n",
      "Test: [90/313]\tTime 0.663 (0.912)\tLoss 0.6270 (0.6292)\tAccuracy 65.625 (65.797)\n",
      "Test: [100/313]\tTime 1.163 (0.928)\tLoss 0.5922 (0.6283)\tAccuracy 71.875 (65.934)\n",
      "Test: [110/313]\tTime 0.735 (0.927)\tLoss 0.5980 (0.6270)\tAccuracy 65.625 (66.075)\n",
      "Test: [120/313]\tTime 1.525 (0.950)\tLoss 0.5666 (0.6262)\tAccuracy 75.000 (66.142)\n",
      "Test: [130/313]\tTime 0.793 (0.957)\tLoss 0.6055 (0.6269)\tAccuracy 68.750 (66.054)\n",
      "Test: [140/313]\tTime 0.695 (0.957)\tLoss 0.5961 (0.6273)\tAccuracy 71.875 (65.980)\n",
      "Test: [150/313]\tTime 0.703 (0.950)\tLoss 0.6586 (0.6267)\tAccuracy 62.500 (66.101)\n",
      "Test: [160/313]\tTime 0.812 (0.963)\tLoss 0.6318 (0.6244)\tAccuracy 65.625 (66.479)\n",
      "Test: [170/313]\tTime 0.731 (0.953)\tLoss 0.7058 (0.6252)\tAccuracy 56.250 (66.356)\n",
      "Test: [180/313]\tTime 1.380 (0.955)\tLoss 0.5622 (0.6253)\tAccuracy 75.000 (66.316)\n",
      "Test: [190/313]\tTime 0.705 (0.953)\tLoss 0.7402 (0.6256)\tAccuracy 50.000 (66.263)\n",
      "Test: [200/313]\tTime 0.955 (0.948)\tLoss 0.5570 (0.6264)\tAccuracy 78.125 (66.138)\n",
      "Test: [210/313]\tTime 1.457 (0.949)\tLoss 0.6202 (0.6259)\tAccuracy 65.625 (66.217)\n",
      "Test: [220/313]\tTime 0.662 (0.949)\tLoss 0.7468 (0.6276)\tAccuracy 46.875 (65.950)\n",
      "Test: [230/313]\tTime 0.723 (0.954)\tLoss 0.6646 (0.6267)\tAccuracy 59.375 (66.098)\n",
      "Test: [240/313]\tTime 1.326 (0.956)\tLoss 0.6101 (0.6264)\tAccuracy 68.750 (66.144)\n",
      "Test: [250/313]\tTime 0.751 (0.965)\tLoss 0.5705 (0.6268)\tAccuracy 75.000 (66.123)\n",
      "Test: [260/313]\tTime 0.719 (0.962)\tLoss 0.5797 (0.6263)\tAccuracy 71.875 (66.188)\n",
      "Test: [270/313]\tTime 1.126 (0.962)\tLoss 0.4999 (0.6258)\tAccuracy 84.375 (66.225)\n",
      "Test: [280/313]\tTime 1.055 (0.961)\tLoss 0.6899 (0.6256)\tAccuracy 56.250 (66.237)\n",
      "Test: [290/313]\tTime 0.637 (0.957)\tLoss 0.7453 (0.6270)\tAccuracy 46.875 (66.033)\n",
      "Test: [300/313]\tTime 0.872 (0.961)\tLoss 0.6545 (0.6271)\tAccuracy 62.500 (66.030)\n",
      "Test: [310/313]\tTime 0.890 (0.963)\tLoss 0.6067 (0.6270)\tAccuracy 68.750 (66.027)\n",
      "Epoch: [8][0/313]\tTime 1.022 (1.022)\tData 0.682 (0.682)\tLoss 0.6659 (0.6659)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [8][10/313]\tTime 1.027 (1.154)\tData 0.713 (0.824)\tLoss 0.6002 (0.6474)\tAccuracy 65.625 (63.636)\n",
      "Epoch: [8][20/313]\tTime 0.912 (1.144)\tData 0.636 (0.817)\tLoss 0.5770 (0.6281)\tAccuracy 75.000 (66.815)\n",
      "Epoch: [8][30/313]\tTime 0.848 (1.227)\tData 0.579 (0.877)\tLoss 0.5329 (0.6283)\tAccuracy 81.250 (66.935)\n",
      "Epoch: [8][40/313]\tTime 1.256 (1.231)\tData 0.910 (0.879)\tLoss 0.5978 (0.6311)\tAccuracy 68.750 (66.692)\n",
      "Epoch: [8][50/313]\tTime 1.094 (1.230)\tData 0.767 (0.877)\tLoss 0.5638 (0.6301)\tAccuracy 71.875 (66.667)\n",
      "Epoch: [8][60/313]\tTime 1.300 (1.212)\tData 0.917 (0.864)\tLoss 0.7499 (0.6363)\tAccuracy 50.000 (65.932)\n",
      "Epoch: [8][70/313]\tTime 1.293 (1.221)\tData 0.920 (0.870)\tLoss 0.5819 (0.6398)\tAccuracy 71.875 (65.493)\n",
      "Epoch: [8][80/313]\tTime 1.066 (1.213)\tData 0.751 (0.865)\tLoss 0.6050 (0.6373)\tAccuracy 71.875 (65.779)\n",
      "Epoch: [8][90/313]\tTime 1.332 (1.216)\tData 0.947 (0.867)\tLoss 0.5996 (0.6322)\tAccuracy 68.750 (66.415)\n",
      "Epoch: [8][100/313]\tTime 0.939 (1.218)\tData 0.659 (0.869)\tLoss 0.7299 (0.6312)\tAccuracy 53.125 (66.522)\n",
      "Epoch: [8][110/313]\tTime 1.366 (1.217)\tData 0.994 (0.868)\tLoss 0.6832 (0.6300)\tAccuracy 53.125 (66.554)\n",
      "Epoch: [8][120/313]\tTime 0.993 (1.209)\tData 0.708 (0.862)\tLoss 0.5045 (0.6326)\tAccuracy 84.375 (66.348)\n",
      "Epoch: [8][130/313]\tTime 1.242 (1.207)\tData 0.867 (0.860)\tLoss 0.7257 (0.6339)\tAccuracy 50.000 (66.221)\n",
      "Epoch: [8][140/313]\tTime 1.094 (1.215)\tData 0.748 (0.866)\tLoss 0.6833 (0.6330)\tAccuracy 56.250 (66.246)\n",
      "Epoch: [8][150/313]\tTime 1.536 (1.227)\tData 1.099 (0.872)\tLoss 0.6075 (0.6331)\tAccuracy 71.875 (66.370)\n",
      "Epoch: [8][160/313]\tTime 1.601 (1.232)\tData 1.153 (0.877)\tLoss 0.6379 (0.6309)\tAccuracy 62.500 (66.595)\n",
      "Epoch: [8][170/313]\tTime 0.885 (1.235)\tData 0.626 (0.878)\tLoss 0.6489 (0.6322)\tAccuracy 62.500 (66.447)\n",
      "Epoch: [8][180/313]\tTime 1.787 (1.243)\tData 1.281 (0.885)\tLoss 0.6089 (0.6318)\tAccuracy 62.500 (66.454)\n",
      "Epoch: [8][190/313]\tTime 1.532 (1.252)\tData 1.090 (0.890)\tLoss 0.7040 (0.6331)\tAccuracy 59.375 (66.279)\n",
      "Epoch: [8][200/313]\tTime 1.115 (1.246)\tData 0.821 (0.887)\tLoss 0.6305 (0.6334)\tAccuracy 62.500 (66.262)\n",
      "Epoch: [8][210/313]\tTime 1.374 (1.245)\tData 0.988 (0.886)\tLoss 0.6376 (0.6348)\tAccuracy 68.750 (66.129)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][220/313]\tTime 1.322 (1.263)\tData 0.945 (0.899)\tLoss 0.6229 (0.6338)\tAccuracy 65.625 (66.205)\n",
      "Epoch: [8][230/313]\tTime 0.892 (1.259)\tData 0.626 (0.897)\tLoss 0.7040 (0.6333)\tAccuracy 59.375 (66.261)\n",
      "Epoch: [8][240/313]\tTime 1.274 (1.265)\tData 0.908 (0.901)\tLoss 0.6928 (0.6337)\tAccuracy 59.375 (66.196)\n",
      "Epoch: [8][250/313]\tTime 1.054 (1.267)\tData 0.718 (0.903)\tLoss 0.7051 (0.6338)\tAccuracy 56.250 (66.173)\n",
      "Epoch: [8][260/313]\tTime 1.114 (1.266)\tData 0.802 (0.902)\tLoss 0.6503 (0.6336)\tAccuracy 65.625 (66.212)\n",
      "Epoch: [8][270/313]\tTime 1.115 (1.264)\tData 0.775 (0.901)\tLoss 0.6322 (0.6347)\tAccuracy 62.500 (66.121)\n",
      "Epoch: [8][280/313]\tTime 0.952 (1.264)\tData 0.677 (0.900)\tLoss 0.6500 (0.6344)\tAccuracy 65.625 (66.125)\n",
      "Epoch: [8][290/313]\tTime 1.548 (1.261)\tData 1.084 (0.898)\tLoss 0.5907 (0.6347)\tAccuracy 75.000 (66.076)\n",
      "Epoch: [8][300/313]\tTime 1.176 (1.270)\tData 0.832 (0.905)\tLoss 0.6690 (0.6356)\tAccuracy 62.500 (65.926)\n",
      "Epoch: [8][310/313]\tTime 1.376 (1.268)\tData 0.961 (0.903)\tLoss 0.6230 (0.6347)\tAccuracy 65.625 (66.047)\n",
      "Test: [0/313]\tTime 0.781 (0.781)\tLoss 0.6778 (0.6778)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/313]\tTime 1.004 (0.850)\tLoss 0.5703 (0.6413)\tAccuracy 75.000 (63.636)\n",
      "Test: [20/313]\tTime 0.911 (0.860)\tLoss 0.6051 (0.6418)\tAccuracy 68.750 (63.393)\n",
      "Test: [30/313]\tTime 0.842 (0.877)\tLoss 0.6985 (0.6410)\tAccuracy 56.250 (63.810)\n",
      "Test: [40/313]\tTime 0.970 (0.902)\tLoss 0.6768 (0.6402)\tAccuracy 59.375 (63.948)\n",
      "Test: [50/313]\tTime 1.282 (0.905)\tLoss 0.6228 (0.6385)\tAccuracy 68.750 (64.277)\n",
      "Test: [60/313]\tTime 1.060 (0.908)\tLoss 0.6442 (0.6344)\tAccuracy 62.500 (65.010)\n",
      "Test: [70/313]\tTime 1.067 (0.914)\tLoss 0.6213 (0.6328)\tAccuracy 65.625 (65.141)\n",
      "Test: [80/313]\tTime 0.645 (0.910)\tLoss 0.7111 (0.6306)\tAccuracy 53.125 (65.432)\n",
      "Test: [90/313]\tTime 0.637 (0.898)\tLoss 0.6324 (0.6286)\tAccuracy 65.625 (65.694)\n",
      "Test: [100/313]\tTime 1.154 (0.909)\tLoss 0.5963 (0.6278)\tAccuracy 71.875 (65.873)\n",
      "Test: [110/313]\tTime 0.706 (0.911)\tLoss 0.5987 (0.6265)\tAccuracy 65.625 (66.047)\n",
      "Test: [120/313]\tTime 1.482 (0.913)\tLoss 0.5789 (0.6256)\tAccuracy 75.000 (66.116)\n",
      "Test: [130/313]\tTime 0.666 (0.913)\tLoss 0.6099 (0.6262)\tAccuracy 68.750 (66.031)\n",
      "Test: [140/313]\tTime 0.653 (0.915)\tLoss 0.5981 (0.6266)\tAccuracy 71.875 (65.980)\n",
      "Test: [150/313]\tTime 0.730 (0.911)\tLoss 0.6582 (0.6259)\tAccuracy 62.500 (66.101)\n",
      "Test: [160/313]\tTime 0.820 (0.933)\tLoss 0.6314 (0.6236)\tAccuracy 65.625 (66.479)\n",
      "Test: [170/313]\tTime 0.712 (0.925)\tLoss 0.6989 (0.6244)\tAccuracy 56.250 (66.356)\n",
      "Test: [180/313]\tTime 1.298 (0.928)\tLoss 0.5622 (0.6245)\tAccuracy 75.000 (66.316)\n",
      "Test: [190/313]\tTime 0.648 (0.928)\tLoss 0.7258 (0.6247)\tAccuracy 50.000 (66.263)\n",
      "Test: [200/313]\tTime 0.935 (0.923)\tLoss 0.5601 (0.6255)\tAccuracy 78.125 (66.154)\n",
      "Test: [210/313]\tTime 1.065 (0.923)\tLoss 0.6242 (0.6251)\tAccuracy 65.625 (66.247)\n",
      "Test: [220/313]\tTime 0.589 (0.925)\tLoss 0.7396 (0.6266)\tAccuracy 46.875 (65.979)\n",
      "Test: [230/313]\tTime 0.728 (0.932)\tLoss 0.6646 (0.6259)\tAccuracy 59.375 (66.098)\n",
      "Test: [240/313]\tTime 1.303 (0.935)\tLoss 0.6091 (0.6255)\tAccuracy 68.750 (66.157)\n",
      "Test: [250/313]\tTime 0.743 (0.942)\tLoss 0.5739 (0.6259)\tAccuracy 75.000 (66.135)\n",
      "Test: [260/313]\tTime 0.698 (0.937)\tLoss 0.5857 (0.6254)\tAccuracy 71.875 (66.212)\n",
      "Test: [270/313]\tTime 1.056 (0.938)\tLoss 0.5064 (0.6249)\tAccuracy 84.375 (66.236)\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "train_losses, train_accuracies = [], []\n",
    "valid_losses, valid_accuracies = [], []\n",
    "for epoch in range(20):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, criterion, optimizer, epoch)\n",
    "    valid_loss, valid_accuracy, valid_results = evaluate(model, device, valid_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "\n",
    "    is_best = valid_accuracy > best_val_acc  \n",
    "    if is_best:\n",
    "        best_val_acc = valid_accuracy\n",
    "        torch.save(model, os.path.join(\"MyVariableRNN.pth\"))\n",
    "\n",
    "plot_learning_curves(train_losses, valid_losses, train_accuracies, valid_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(os.path.join(PATH_OUTPUT, \"MyVariableRNN.pth\"))\n",
    "class_names = ['Alive', 'Dead']\n",
    "test_loss, test_accuracy, test_results = evaluate(best_model, device, valid_loader, criterion)\n",
    "plot_confusion_matrix(test_results, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
